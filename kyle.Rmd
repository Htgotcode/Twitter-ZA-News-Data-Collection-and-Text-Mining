---
title: "R Notebook"
output: html_notebook
---

What tweets got the most attention.
frequency of tweets posted on a topic


```{r}
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
library(vader)
library(topicmodels)
library(quanteda)

origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)

api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
  app = "KyleResearchApp",
  consumer_key = api_key,
  consumer_secret = api_secret,
  access_token = access_token,
  access_secret = access_secret
)
```

```{r}
#Get tweets
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- media_agency_df %>% 
  mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>% 
  mutate(rbind(rtweet::get_timeline("ewnupdates", n = 3200))) %>% 
  mutate(rbind(rtweet::get_timeline("TimesLive", n = 3200))) %>% 
  mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))

write_as_csv(media_agency_df, "data_in/media_agency_tweets")
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")

media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
```


# Comparing Tweet Archives


```{r}
ggplot(media_agency_df, aes(x = created_at, fill = screen_name)) +
  geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +
  facet_wrap(~screen_name, ncol = 1)
```

```{r Clean up}

covid_dictionary <- c("herd", "immunity", "incubation", "job", "loss", "Kits", "lockdown", "mask", "N95", "outbreak", "pandemic", "quarantine", "recovery", "sanitiser", "transmission", "Underlying", "conditions", "Ventilators", "WHO", "xenophobia", "youTube", "zoonotic", "stay-at-home", "covid", "coronavirus", "hyrdoxychloroquine", "asymptomatic", "frontline", "virus", "self-isolation", "disinfectant", "shelter-in-place", "masks", "SARS-CoV-2", "ICU", "corona", "reopen", "distancing", "covering", "furlough", "tracer", "easing", "remdesivir", "mail-in", "hornet", "antibody", "in-person", "defund", "racism", "looting", "loot", "reopen", "two-metre", "pandemic", "looter", "distancing", "dexamethasone", "racial", "vaccine")

#JUST tidy
media_agency_df <- media_agency_df %>% 
  mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
         text = gsub("&amp", "", text),
         text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
         text = gsub("@\\w+", "", text),
         text = gsub("[[:punct:]]", "", text),
         text = gsub("[[:digit:]]", "", text),
         text = gsub("http\\w+", "", text),
         text = gsub("[ \t]{2,}", "", text),
         text = gsub("^\\s+|\\s+$", "", text),
         text = gsub("enca", "", text),
         text = gsub("dstv", "", text),
         text = gsub("sabcnews", "", text),
         text = gsub("&amp", "", text)) %>% 
  mutate(text = str_replace_all(text," "," "),
         text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
         text = str_replace_all(text,"#[a-z,A-Z]*"," "),
         text = str_replace_all(text,"@[a-z,A-Z]*"," "))
  
#tidy df and unnest
tidy_covid_media_df <- media_agency_df %>% 
  #filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>% 
  filter(!str_detect(text, "^RT")) %>% 
  mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>% 
  unnest_tokens(word, text, token = "tweets") %>%
  filter(!word %in% stop_words$word,
         !word %in% str_remove_all(stop_words$word, "'"),
         str_detect(word, "[a-z]"),
         !(word =="#sabcnews" |
             word =="#enca" |
             word =="https" |
             word =="#dstv403" |
             word =="t.co" |
             word =="rt" |
             word =="amp"))



#top words
top_words <- tidy_covid_media_df %>% 
  anti_join(stop_words) %>% 
  count(word) %>% 
  arrange(desc(n))
top_words %>% 
  slice(1:20) %>% 
  ggplot(aes(reorder(word, -n), n, fill = word)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 60, hjust = 1, size = 13),
    plot.title = element_text(hjust = 0.5, size = 18)
    ) +
  ylab("Frequency") +
  xlab ("") +
  ggtitle("Most frequent media agency tweets") +
  guides(fill=FALSE)

#tf-idf
tidy_covid_media_tfidf <- tidy_covid_media_df %>% 
  select(created_at, word) %>% 
  count(word, created_at) %>% 
  bind_tf_idf(word, created_at, n)

#top_tfidf
tidy_covid_media_tfidf %>% 
  slice(-(1:582)) %>% 
  arrange(desc(tf_idf))


#calculate a frequency for each person and word
frequency <- tidy_media_agency_df %>% 
  group_by(screen_name) %>% 
  count(word, sort = TRUE) %>% 
  left_join(tidy_media_agency_df %>% 
              group_by(screen_name) %>% 
              summarise(total = n())) %>%
  mutate(freq = n/total)

#plot those frequencies on the x- and y-axes 
frequency <- frequency %>% 
  select(screen_name, word, freq) %>% 
  pivot_wider(names_from = screen_name, values_from = freq)

#yearly 
```

```{r VADER}
vader_df <- vader_df(media_agency_df$text)
write_as_csv(vader_df, "data_in/vader_df")

vader_df <- read_csv("data_in/vader_df.csv")
vader_df <- vader_df %>% mutate("X1" = row_number())
sentimentr_df <- read_csv("data_in/sentimentr_data.csv")
media_vader_df <- media_agency_df %>% left_join(vader_df, by = "X1")

media_vader_df %>%
  select(status_id, screen_name, text.x, compound, pos, neu, neg)

media_vader_df %>% 
  select(status_id, screen_name, text.x, compound, pos, neu, neg) %>% 
  ggplot() +
  geom_point(aes(text.x, compound)) +
  facet_wrap(~screen_name)

```
# topics covered, sentiment in general
(either with specific lexicons for relevant keywords or other sentiment lexicons/dictionaries),
sentiment of specific topics, frequency of posts, network interaction metrics, etc.

```{r Topic Modelling}
tidy_matrix <- tidy_covid_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)

media_lda <- LDA(tidy_matrix, k = 5, control = list(seed = 1234))

media_topics <- tidy(media_lda, matrix = "beta")

media_top_terms <- media_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)

media_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>% 
  # pivot_wider(id_cols = term, names_from = topic, values_from = beta) %>% 
  # rename("Covid Spread in Gauteng" = 2, "Vaccines" = 3, "idk" = 4, "Health in Africa" = 5) %>% 
  # pivot_longer(cols = c(2,3,4,5), names_to = "topic", values_to = "beta") %>% 
  # drop_na() %>% 
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~topic, scales = "free") +
  scale_y_reordered()
```

