---
title: "R Notebook"
output: html_notebook
---

What tweets got the most attention.
frequency of tweets posted on a topic


```{r}
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
library(vader)
library(topicmodels)
library(quanteda)
library(lubridate)
library(zoo)
library(plotly)

origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)

api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
  app = "KyleResearchApp",
  consumer_key = api_key,
  consumer_secret = api_secret,
  access_token = access_token,
  access_secret = access_secret
)
```

```{r}
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- media_agency_df %>% 
  mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>% 
  mutate(rbind(rtweet::get_timeline("ewnupdates", n = 3200))) %>% 
  mutate(rbind(rtweet::get_timeline("TimesLive", n = 3200))) %>% 
  mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))

write_as_csv(media_agency_df, "data_in/media_agency_tweets")
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")

media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
```


# Comparing Tweet Archives


```{r}
ggplot(media_agency_df, aes(x = created_at, fill = screen_name)) +
  geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +
  facet_wrap(~screen_name, ncol = 1)
```

```{r Clean up}

covid_dictionary <- c("herd", "immunity", "incubation", "job", "loss", "Kits", "lockdown", "mask", "N95", "outbreak", "pandemic", "quarantine", "recovery", "sanitiser", "transmission", "Underlying", "conditions", "Ventilators", "WHO", "xenophobia", "youTube", "zoonotic", "stay-at-home", "covid", "coronavirus", "hyrdoxychloroquine", "asymptomatic", "frontline", "virus", "self-isolation", "disinfectant", "shelter-in-place", "masks", "SARS-CoV-2", "ICU", "corona", "reopen", "distancing", "covering", "furlough", "tracer", "easing", "remdesivir", "mail-in", "hornet", "antibody", "in-person", "defund", "racism", "looting", "loot", "reopen", "two-metre", "pandemic", "looter", "distancing", "dexamethasone", "racial", "vaccine")

#JUST tidy
media_agency_df <- media_agency_df %>% 
  mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
         text = gsub("&amp", "", text),
         text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
         text = gsub("@\\w+", "", text),
         text = gsub("[[:punct:]]", "", text),
         text = gsub("[[:digit:]]", "", text),
         text = gsub("http\\w+", "", text),
         text = gsub("[ \t]{2,}", "", text),
         text = gsub("^\\s+|\\s+$", "", text),
         text = gsub("enca", "", text),
         text = gsub("dstv", "", text),
         text = gsub("sabcnews", "", text),
         text = gsub("&amp", "", text)) %>% 
  mutate(text = str_replace_all(text," "," "),
         text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
         text = str_replace_all(text,"#[a-z,A-Z]*"," "),
         text = str_replace_all(text,"@[a-z,A-Z]*"," "))
  
#tidy df and unnest
tidy_covid_media_df <- media_agency_df %>% 
  filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
  filter(!str_detect(text, "^RT")) %>%
  mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
  unnest_tokens(word, text, token = "tweets") %>% 
  filter(!word %in% stop_words$word,
         !word %in% str_remove_all(stop_words$word, "'"),
         str_detect(word, "[a-z]"),
         !(word =="sabcnews" |
             word =="enca" |
             word =="https" |
             word =="dstv" |
             word =="sabckzn" |
             word =="anc" |
             word =="south" |
             word =="africa" |
             word =="dstv403" |
             word =="t.co" |
             word =="itus" |
             word =="rt" |
             word =="amp"))

```

```{r tf-idf}
#top words
top_words <- tidy_covid_media_df %>% 
  anti_join(stop_words) %>% 
  count(word) %>% 
  arrange(desc(n))
top_words %>% 
  slice(1:20) %>% 
  ggplot(aes(reorder(word, -n), n, fill = word)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 60, hjust = 1, size = 13),
    plot.title = element_text(hjust = 0.5, size = 18)
    ) +
  ylab("Frequency") +
  xlab ("") +
  ggtitle("Most frequent media agency tweets") +
  guides(fill=FALSE)

#tf-idf
tidy_covid_media_tfidf <- tidy_covid_media_df %>% 
  select(created_at, word) %>% 
  count(word, created_at) %>% 
  bind_tf_idf(word, created_at, n)

#top_tfidf
tidy_covid_media_tfidf %>% 
  slice(-(1:582)) %>% 
  arrange(desc(tf_idf))


#calculate a frequency for each person and word
frequency <- tidy_covid_media_df %>% 
  group_by(screen_name) %>% 
  count(word, sort = TRUE) %>% 
  left_join(tidy_covid_media_df %>% 
              group_by(screen_name) %>% 
              summarise(total = n())) %>%
  mutate(freq = n/total)

#plot those frequencies on the x- and y-axes 
frequency <- frequency %>% 
  select(screen_name, word, freq) %>% 
  pivot_wider(names_from = screen_name, values_from = freq)

#yearly 
```

```{r VADER}
vader_df <- vader_df(media_agency_df$text)
write_as_csv(vader_df, "data_in/vader_covid_df")

vader_df <- read_csv("data_in/vader_df.csv")
vader_covid_df <- read_csv("data_in/vader_covid_df.csv")
vader_df <- vader_df %>% mutate("X1" = row_number())
sentimentr_df <- read_csv("data_in/sentimentr_data.csv")
media_vader_df <- media_agency_df %>% left_join(vader_df, by = "X1")

#sentiment
ggplot(data=media_vader_df, aes(x=created_at, y=rollmean(compound, 30,  na.pad=TRUE))) +
       geom_line(color="pink", size=.5)+
  geom_smooth() +
  theme_minimal()+
  facet_wrap(~screen_name) +
  scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
  ylim(c(-0.4, 0.4))

#sentiment
ggplot(data=media_vader_df, aes(x=created_at, fill = screen_name)) +
  stat_smooth(media_vader_df %>% filter(screen_name == "News24"), mapping =  aes(y = mean(compound)))+
  stat_smooth(media_vader_df %>% filter(screen_name == "ewnupdates"), mapping =  aes(y = compound))+
  stat_smooth(media_vader_df %>% filter(screen_name == "eNCA"), mapping =  aes(y = compound))+
  stat_smooth(media_vader_df %>% filter(screen_name == "SABCNews"), mapping =  aes(y = compound))+
  stat_smooth(media_vader_df %>% filter(screen_name == "TimesLIVE"), mapping =  aes(y = compound))+
  theme_minimal()+
  scale_y_continuous(expand = c(0,0), breaks = c(-0.1, 0)) 
  

ggplot(data=media_vader_df, aes(x=created_at, colour = screen_name)) +
  geom_line(media_vader_df %>% filter(screen_name == "News24"), mapping =  aes(y = rollmean(compound, k = 30, na.pad = TRUE)))+
  geom_line(media_vader_df %>% filter(screen_name == "ewnupdates"), mapping = aes(y = rollmean(compound, k = 30, na.pad = TRUE)))+
  geom_line(media_vader_df %>% filter(screen_name == "eNCA"), mapping = aes(y = rollmean(compound, k = 30, na.pad = TRUE)))+
  geom_line(media_vader_df %>% filter(screen_name == "SABCNews"), mapping = aes(y = rollmean(compound, k = 30, na.pad = TRUE)))+
  geom_line(media_vader_df %>% filter(screen_name == "TimesLIVE"), mapping = aes(y = rollmean(compound, k = 30, na.pad = TRUE)))+
  theme_minimal()+
  scale_y_continuous(expand = c(0,0)) 

ggplot(media_vader_df %>% arrange(compound) %>% mutate(X1 = factor(X1, levels = X1)), aes(x=X1)) +
  geom_point(mapping =  aes(y = compound)) +
  theme_minimal()+
  scale_y_continuous(expand = c(0,0)) 

```

```{r Interactions}
media_vader_df %>% select(favorite_count, retweet_count) %>% mutate(favorite_count + retweet_count)
media_vader_df %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(sum = sum(favorite_count + retweet_count)) 
 media_vader_df %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at, screen_name) %>% mutate(retweet_daily = sum(retweet_count), favorite_daily = sum(favorite_count)) %>% ungroup()

plot <- media_vader_df %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(retweet_daily = sum(retweet_count), favorite_daily = sum(favorite_count), sum = sum(favorite_count + retweet_count)) %>% 
  ggplot(aes(created_at)) +
  geom_ribbon(aes(ymin = 0, ymax = retweet_daily, y = sum, fill = "blue"))
  
ggplotly(plot)

plot <- media_vader_df %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(sum = sum(favorite_count + retweet_count)) %>% 
  ggplot(aes(created_at, sum)) +
  geom_ribbon(aes(ymin = 0, ymax = sum)) 
  
ggplotly(plot)

media_vader_df %>% 
   filter(screen_name == "SABCNews") %>% 
  slice_max(favorite_count + retweet_count + quoted_retweet_count) 

class(media_vader_df$created_at)

# top tweets
# eNCA Call for ministers over 60 to resign https://t.co/wlEjJGEpuk
# ewn KZN boy (5) gets home safely after taxi driver kicks him out for not having fare https://t.co/tfO9axodar https://t.co/yx3YjV9vao
# TimesLIVE	Do you approve of Duduzane running for president? https://t.co/hCDVQGHRWy
# News24 Coca-Cola lost $4 billion in market value after Cristiano Ronaldo suggested people drink water instead | @BISouthAfrica
# SABCNews BREAKING NEWS: King of Eswatini has fled amid public violence in the country https://t.co/1jv8vVCw9d
```

```{r Topic Modelling}
tidy_matrix <- tidy_covid_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)

media_lda <- LDA(tidy_matrix, k = 5, control = list(seed = 1234))

media_topics <- tidy(media_lda, matrix = "beta")

media_top_terms <- media_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)

media_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  pivot_wider(id_cols = term, names_from = topic, values_from = beta) %>%
  rename("Nations Address" = 2, "Getting vaccinated for third wave" = 3, "Announcement of vaccine" = 4, "Covid-19: South Africa update" = 5, "Vaccination distributions" = 6) %>%
  pivot_longer(cols = c(2,3,4,5,6), names_to = "topic", values_to = "beta") %>%
  drop_na() %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()
```

```{r Gap k justify}

install.packages("ldatuning")


install.packages("devtools")
devtools::install_github("nikita-moor/ldatuning")


library("ldatuning")


library("topicmodels")
data("AssociatedPress", package="topicmodels")
dtm <- AssociatedPress[1:10, ]


result <- FindTopicsNumber(
  tidy_matrix,
  topics = seq(from = 2, to = 15, by = 1),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 77),
  mc.cores = 2L,
  verbose = TRUE
)


##  fit models... done.
##  calculate metrics:
##   Griffiths2004... done.
##   CaoJuan2009... done.
##   Arun2010... done.
##   Deveaud2014... done.


FindTopicsNumber_plot(result)
```

