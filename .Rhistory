mutate(created_at = as.POSIXct(created_at, origin = "1970-01-01"))
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = as.POSIXct(created_at, origin = "1970-01-01"))
View(media_agency_df)
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = ymd_hms(as.POSIXct(created_at, origin = "1970-01-01")))
library(lubridate
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = ymd_hms(as.POSIXct(created_at, origin = "1970-01-01")))
library(readr)
library(lubridate)
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = ymd_hms(as.POSIXct(created_at, origin = "1970-01-01")))
View(media_agency_df)
ggplot(tweets, aes(x = created_at, fill = screen_name)) +
geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 1)
ggplot(media_agency_df, aes(x = created_at, fill = screen_name)) +
geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 1)
remove_reg <- "&amp;|&lt;|&gt;"
tidy_media_agency_df <- media_agency_df %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
View(tidy_media_agency_df)
media_agency_df <- read_csv("data_in/media_agency_tweets") %>%
mutate(created_at = ymd_hms(as.POSIXct(created_at, origin = "1970-01-01")))
remove_reg <- "&amp;|&lt;|&gt;"
tidy_media_agency_df <- media_agency_df %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
View(tidy_media_agency_df)
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_tweets %>%
group_by(person) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(person) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(screen_name) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
View(frequency)
tidy_media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(screen_name) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
frequency <- frequency %>%
select(screen_name, word, freq) %>%
pivot_wider(names_from = screen_name, values_from = freq)
View(frequency)
ggplot(frequency, aes(News24, ewnupdates)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
ggplot(frequency, aes(News24, ewnupdates)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
ggplot(frequency, aes(News24, ewnupdates)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
word %in% "covid",
word %in% "coronavirus")
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "covid",
!word %in% "coronavirus")
View(tidy_covid_media_df)
View(media_agency_df)
write_as_csv(media_agency_df, "data_in/media_agency_tweets")
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
View(media_agency_df)
install.packages("vader")
#tidy df
remove_reg <- "&amp;|&lt;|&gt;"
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
#calculate a frequency for each person and word
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(screen_name) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
#plot those frequencies on the x- and y-axes
frequency <- frequency %>%
select(screen_name, word, freq) %>%
pivot_wider(names_from = screen_name, values_from = freq)
#yearly
?vader
library(vader)
?vader_df
vader_df(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
select(user_id, status_id, created_at, screen_name, text)
#tidy df
remove_reg <- "&amp;|&lt;|&gt;"
tidy_covid_media_df <- media_agency_df %>%
select(user_id, status_id, created_at, screen_name, text)
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
#tidy df
remove_reg <- "&amp;|&lt;|&gt;"
tidy_covid_media_df <- media_agency_df %>%
select(user_id, status_id, created_at, screen_name, text)
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
#tidy df
remove_reg <- "&amp;|&lt;|&gt;"
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
#calculate a frequency for each person and word
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(screen_name) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
#plot those frequencies on the x- and y-axes
frequency <- frequency %>%
select(screen_name, word, freq) %>%
pivot_wider(names_from = screen_name, values_from = freq)
#yearly
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets")
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
View(tidy_covid_media_df)
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
#tidy df
remove_reg <- "&amp;|&lt;|&gt;"
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
#calculate a frequency for each person and word
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(screen_name) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
#plot those frequencies on the x- and y-axes
frequency <- frequency %>%
select(screen_name, word, freq) %>%
pivot_wider(names_from = screen_name, values_from = freq)
#yearly
View(tidy_covid_media_df)
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
View(media_agency_df)
remove_reg <- "&amp;|&lt;|&gt;"
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text))
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT"))
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg))
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets")
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus") %>%
anti_join(media_agency_df)
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus") %>%
left_join(media_agency_df)
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus") %>%
anti_join(get_stopwords())
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus") %>%
anti_join(get_stopwords())
View(tidy_covid_media_df)
media_agency_df %>%  unnest_tokens(word, text, token = "tweets")
media_agency_df %>%  unnest_tokens(word, text, token = "tweets") %>% anti_join(get_stopwords())
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
vader_df(tidy_covid_media_df$word)
vader_df <- vader_df(tidy_covid_media_df$word)
View(vader_df)
tidy_covid_media_df %>% left_join(vader_df, by = word)
tidy_covid_media_df %>% left_join(vader_df, by = "word")
tidy_covid_media_df %>% left_join(vader_df, by = `word`)
tidy_covid_media_df %>% left_join(vader_df, by = `word`)
tidy_covid_media_df %>% left_join(vader_df
tidy_covid_media_df %>% left_join(vader_df)
tidy_covid_media_df %>% left_join(vader_df)
vader_df <- rename("word" = text)
vader_df <- vader_df %>% rename("word" = text)
View(vader_df)
tidy_covid_media_df %>% left_join(vader_df)
tidy_covid_media_df %>% left_join(vader_df, by = "word")
tidy_covid_media_df %>% merge(vader_df)
tidy_covid_media_df %>% merge(vader_df, by = "word", all.x = TRUE, allow.cartesian=TRUE)
tidy_covid_media_df %>% left_join(vader_df)
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
library(vader)
tidy_covid_media_df %>% left_join(vader_df)
tidy_covid_media_df <- tidy_covid_media_df %>% left_join(vader_df)
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
library(vader)
origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)
api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
app = "KyleResearchApp",
consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_secret
)
rtweet::emojis
rtweet::get_collections("News24", n=100)
?get_collections
media_tweets_df[grep("Covid", media_tweets_df$text) ]
media_agency_df[grep("Covid", media_tweets_df$text) ]
media_agency_df[grep("Covid", media_agency_df$text) ]
filtered_tweets <- media_agency_df[grep("covid", media_agency_df$text), ignore.case = TRUE]
View(filtered_tweets)
install.packages(c("cli", "colorspace", "gargle"))
media_media_df %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]]
media_agency_df %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]]
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
library(vader)
media_agency_df %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]]
media_agency_df %>%
str_extract_all(media_agency_df$text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]]
media_agency_df %>%
str_extract_all(media_agency_df$text[0], "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")
media_agency_df %>%
str_extract_all(media_agency_df$text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")
str_extract_all(media_agency_df$text, "([:alnum:]+\\s)*India[[:alnum:]\\s]*\\.")[[1]]
str_extract_all(media_agency_df$text, "([:alnum:]+\\s)*Covid[[:alnum:]\\s]*\\.")[[1]]
str_extract_all(media_agency_df$text, "([:alnum:]+\\s)*covid[[:alnum:]\\s]*\\.")[[1]]
x <- str_extract_all(media_agency_df$text, "([:alnum:]+\\s)*covid[[:alnum:]\\s]*\\.")[[1]]
x <- str_extract_all(media_agency_df$text, "([:alnum:]+\\s)*covid-19[[:alnum:]\\s]*\\.")[[1]]
x <- str_extract_all(media_agency_df$text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]]
media_agency_df$retweet_count
media_agency_df$favorite_count
media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
View(media_agency_df)
#tidy df
remove_reg <- "&amp;|&lt;|&gt;"
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
