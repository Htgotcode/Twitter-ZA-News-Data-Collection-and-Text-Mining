scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~screen_name, ncol = 2) +
theme(legend.position="none") +
labs(y = "News24", x = NULL)
View(frequency)
ggplot(frequency, aes(x = proportion, y = News24,
color = abs(`News24` - proportion))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~`screen name`, ncol = 2) +
theme(legend.position="none") +
labs(y = "News24", x = NULL)
ggplot(frequency, aes(x = proportion, y = News24,
color = abs(`News24` - proportion))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~screen name, ncol = 2) +
frequency <- bind_rows(mutate(tidy_news24, screen_name = "News24"),
mutate(tidy_eNCA, screen_name = "eNCA")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(screen_name, word) %>%
group_by(screen_name) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
pivot_wider(names_from = screen_name, values_from = proportion) %>%
pivot_longer(`News24`:`eNCA`,
names_to = "screen_name", values_to = "proportion")
ggplot(frequency, aes(x = proportion, y = News24,
color = abs(`News24` - proportion))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~screen_name, ncol = 2) +
theme(legend.position="none") +
labs(y = "News24", x = NULL)
ggplot(frequency, aes(x = proportion, y = News24,
color = abs(News24 - proportion))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~screen_name, ncol = 2) +
theme(legend.position="none") +
labs(y = "News24", x = NULL)
`
frequency <- bind_rows(mutate(tidy_news24, screen_name = "News24"),
mutate(tidy_eNCA, screen_name = "eNCA")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(screen_name, word) %>%
group_by(screen_name) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
pivot_wider(names_from = screen_name, values_from = proportion) %>%
pivot_longer(`News24`:`eNCA`,
frequency <- bind_rows(mutate(tidy_news24, screen_name = "News24"),
mutate(tidy_eNCA, screen_name = "eNCA")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(screen_name, word) %>%
group_by(screen_name) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
pivot_wider(names_from = screen_name, values_from = proportion) %>%
pivot_longer(`News24`:`eNCA`,
names_to = "screen name", values_to = "proportion")
ggplot(frequency, aes(x = proportion, y = News24,
color = abs(`News24` - proportion))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~`screen name`, ncol = 2) +
theme(legend.position="none") +
labs(y = "News24", x = NULL)
ggplot(frequency, aes(x = proportion, y = `News24`,
color = abs(`News24` - proportion))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~`screen name`, ncol = 2) +
theme(legend.position="none") +
labs(y = "News24", x = NULL)
ggplot(frequency, aes(x = proportion, y = `screen name`,
color = proportion)) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~`screen name`, ncol = 2) +
theme(legend.position="none") +
labs(y = "Proportion", x = NULL)
ggplot(frequency, aes(x = proportion, y = `screen name`,
color = proportion)) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~`screen name`, ncol = 2) +
theme(legend.position="none") +
labs(y = "Proportion", x = NULL)
ggplot(frequency, aes(x = proportion, y = word,
color = proportion)) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~`screen name`, ncol = 2) +
theme(legend.position="none") +
labs(y = "Proportion", x = NULL)
```{r fig.height=15}
tidy_news24 <- tweets_news24 %>%
select(screen_name, status_id, text) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
tidy_eNCA <- tweets_eNCA %>%
select(screen_name, status_id, text) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
frequency <- bind_rows(mutate(tidy_news24, screen_name = "News24"),
mutate(tidy_eNCA, screen_name = "eNCA")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(screen_name, word) %>%
group_by(screen_name) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
pivot_wider(names_from = screen_name, values_from = proportion) %>%
pivot_longer(`News24`:`eNCA`,
names_to = "screen name", values_to = "proportion")
ggplot(frequency, aes(x = proportion, y = word,
color = proportion)) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~`screen name`, ncol = 2) +
theme(legend.position="none") +
labs(y = "Proportion", x = NULL)
---
title: "Assignment 2: Data Collection and Text Mining"
output: bookdown::pdf_document2
---
---
title: "Assignment 2: Data Collection and Text Mining"
output: pdf_book
---
library(bookdown)
library(bookdown)
library(bookdown)
---
title: "Assignment 2: Data Collection and Text Mining"
output: bookdown::pdf_book
---
install.packages(c("cli", "colorspace", "curl", "dplyr", "fansi", "mime", "stringi", "tibble", "xfun"))
install.packages(c("cli", "colorspace", "xfun"))
install.packages(c("cli", "colorspace", "xfun"))
install.packages(c("cli", "colorspace", "xfun"))
install.packages(xfun)
install.packages("xfun")
install.packages("xfun")
install.packages("tidytext")
install.packages("tidyverse")
library(tidytext)
library(tidyverse)
media_tweets_df <- read.csv("data_in/media_agency_tweets")
View(media_tweets_df)
data(stop_words)
tidy_media_tweets_df <- media_tweets_df %>%
anti_join(stop_words)
View(stop_words)
picky_mtdf<- media_tweets_df %>%
select(screen_name,text)
tidy_media_tweets_df <- picky_mtdf$text %>%
anti_join(stop_words)
picky_mtdf<- media_tweets_df %>%
select(screen_name,text)
data(stop_words)
tidy_media_tweets_df <- picky_mtdf %>%
anti_join(stop_words)
tidy_media_tweets_df <- picky_mtdf %>%
anti_join(text,stop_words)
tidy_media_tweets_df <- picky_mtdf %>%
anti_join(picky_mtdf$text,stop_words)
picky_mtdf <- picky_mtdf %>%
anti_join(picky_mtdf$text,stop_words)
picky_mtdf<- media_tweets_df %>%
select(screen_name,text) %>%
unnest_tokens("word", text)
picky_mtdf <- picky_mtdf %>%
anti_join(picky_mtdf$text,stop_words)
picky_mtdf <- picky_mtdf %>%
anti_join(stop_words)
View(picky_mtdf)
picky_mtdf%>%
count(word, sort=TRUE)
picky_mtdf%>%
filter(!(word=="https"|
word=="rt"|
word=="t.co"|
word=="amp")) %>%
count(word, sort=TRUE)
nrc_joy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
get_sentiments("nrc")
install.packages("nrc")
install.packages("bing")
install.packages("sentimentr")
install.packages("sentimentr")
library(xfun)
install.packages("nrc")
install.packages("ncr")
install.packages(c("Matrix", "mgcv"))
install.packages("tidytext")
install.packages("tidyverse")
library(tidytext)
install.packages("tidytext")
library(tidytext)
library(stringr)
library(tidytext)
install.packages("stringi")
install.packages("stringi")
library(tidytext)
library(tidyverse)
install.packages("ncr")
install.packages("sentimentr")
install.packages("ncr")
get_sentiments("nrc")
install.packages("nrc")
install.packages("textdata")
get_sentiments("nrc")
get_sentiments("nrc")
get_sentiments("nrc")
library(tidytext)
library(tidyverse)
library(textdata)
get_sentiments("nrc")
library(nrc)
get_sentiments("nrc")
library(sentimentr)
media_tweets_df <- read.csv("data_in/media_agency_tweets")
picky_mtdf<- media_tweets_df %>%
select(screen_name,text) %>%
unnest_tokens("word", text)
data(stop_words)
picky_mtdf <- picky_mtdf %>%
anti_join(stop_words)
picky_mtdf%>%
filter(!(word=="https"|
word=="rt"|
word=="t.co"|
word=="amp")) %>%
count(word, sort=TRUE)
View(media_tweets_df)
View(media_tweets_df)
Covid_tweets<- media_tweets_df%>%
filter(text,str_extract(media_tweets_df,regex("covid",ignore_case = TRUE)))
Covid_tweets<- media_tweets_df%>%
filter(str_extract(media_tweets_df,regex("covid",ignore_case = TRUE)))
set_tweets <- media_tweets_df %>%
select(screen_name,text)
Covid_tweets<- set_tweets%>%
filter(str_extract(set_tweets,regex("covid",ignore_case = TRUE)))
set_tweets <- media_tweets_df %>%
select(text)
Covid_tweets<- set_tweets%>%
filter(str_extract(set_tweets,regex("covid",ignore_case = TRUE)))
Covid_tweets<- set_tweets%>%
str_extract_all("covid","\\w+")
View(Covid_tweets)
View(set_tweets)
search_word<- "Covid-19"
Covid_tweets<- set_tweets%>%
filter(text==search_word)
View(Covid_tweets)
set_tweets %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid_19[[:alnum:]\\s]*\\.")[[1]]
library(stringr)
set_tweets %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid_19[[:alnum:]\\s]*\\.")[[1]]
set_tweets %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid_19[[:alnum:]\\s]*\\.")[[1]]
set_tweets %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]]
set_tweets[grep(pattern = "Covid-19", text, ignore.case = T)]
set_tweets <- media_tweets_df %>%
select(text)
set_tweets <- unlist(strsplit(set_tweets, "\\."))
set_tweets %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")
set_tweets %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]]
View(picky_mtdf)
set_tweets <- media_tweets_df %>%
select(text)
set_tweets <- unlist(strsplit(set_tweets, "\."))
set_tweets <- unlist(strsplit(set_tweets, "\n"))
set_tweets <- unlist(strsplit(set_tweets, "\\."))
set_tweets %>%
stri_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]]
install.packages("stringi")
library(stringi)
set_tweets %>%
stri_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]]
set_tweets %>%
stri_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.",regex)[[1]]
set_tweets %>%
stri_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.",coll = text)[[1]]
set_tweets %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.",coll = text)[[1]]
set_tweets %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]]
set_tweets %>%
c(set_tweets) %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]]
set_tweets %>%
filter(!(word=="https"|
word=="rt"|
word=="t.co"|
word=="amp"))
set_tweets %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1+]]
set_tweets %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[1+]
set_tweets %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]+]
set_tweets <- media_tweets_df %>%
select(screen_name,text)
set_tweets <- media_tweets_df %>%
select(screen_name,text)
filtered_set_tweets <- set_tweets[grep("covid", set_tweets$text), ignore.case = TRUE]
set_tweets <- media_tweets_df %>%
select(screen_name,text)
filtered_set_tweets <- media_tweets_df[grep("covid", media_tweets_df$text), ignore.case = TRUE]
media_tweets_df[grep("covid", media_tweets_df$text), ignore.case = TRUE]
media_tweets_df[grep("Covid", media_tweets_df$text) ]
set_tweets %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]]
filtered_tweets<-media_tweets_df[grep("Covid", media_tweets_df$text), ignore_case= TRUE ]
media_tweets_df <- read.csv("data_in/media_agency_tweets")
media_tweets_df <- read_csv("data_in/media_agency_tweets.csv")
filtered_tweets<- media_tweets_df[grep("covid", media_tweets_df$text), ignore.case = TRUE]
View(filtered_tweets)
media_tweets_df %>%
str_extract_all(text, "([:alnum:]+\\s)*Covid-19[[:alnum:]\\s]*\\.")[[1]]
View(media_tweets_df)
media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
View(media_agency_df)
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="#sabcnews" |
word =="#enca" |
word =="https" |
word =="#dstv403" |
word =="t.co" |
word =="rt" |
word =="amp"))
tidy_matrix <- tidy_covid_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)
install.packages("scales")
library(lubridate)
library(rtweet)
install.packages("rtweet")
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
library(vader)
install.packages("vader")
install.packages("topicmodels")
install.packages("quanteda")
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
library(topicmodels)
library(quanteda)
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="#sabcnews" |
word =="#enca" |
word =="https" |
word =="#dstv403" |
word =="t.co" |
word =="rt" |
word =="amp"))
tidy_matrix <- tidy_covid_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)
media_lda <- LDA(tidy_matrix, k = 2, control = list(seed = 1234))
media_lda
media_topics <- tidy(media_lda, matrix = "beta")
install.packages("reshape2")
library(reshape2)
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="#sabcnews" |
word =="#enca" |
word =="https" |
word =="#dstv403" |
word =="t.co" |
word =="rt" |
word =="amp"))
tidy_matrix <- tidy_covid_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)
media_lda <- LDA(tidy_matrix, k = 2, control = list(seed = 1234))
media_lda
media_topics <- tidy(media_lda, matrix = "beta")
media_topics
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
media_lda <- LDA(tidy_matrix, k = 12, control = list(seed = 1234))
media_lda
media_topics <- tidy(media_lda, matrix = "beta")
media_topics
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
vader_data<- read_csv("data_in/vader_df.csv")
View(vader_data)
mytext<- media_agency_df
mytext<- media_agency_df
mytext <- get_sentences(mytext)
sentiment(mytext)
View(mytext)
media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
mytext<- media_agency_df
mytext <- get_sentences(mytext)
sentiment(mytext)
View(mytext)
mytext<- media_agency_df%>%
select(text)
mytext <- get_sentences(mytext)
sentiment(mytext)
View(vader_data)
View(mytext)
