word =="amp"))
#JUST tidy
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("enca", "", text),
text = gsub("dstv", "", text),
text = gsub("sabcnews", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," ")) %>%
filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE)))
#tidy df and unnest
tidy_covid_media_df <- media_agency_df %>%
filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="sabcnews" |
word =="enca" |
word =="https" |
word =="dstv" |
word =="sabckzn" |
word =="anc" |
word =="south" |
word =="africa" |
word =="dstv403" |
word =="t.co" |
word =="itus" |
word =="rt" |
word =="amp"))
View(media_agency_df)
View(media_agency_df)
#tidy df and unnest
tidy_covid_media_df <- media_agency_df %>%
filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="sabcnews" |
word =="enca" |
word =="https" |
word =="dstv" |
word =="sabckzn" |
word =="anc" |
word =="south" |
word =="africa" |
word =="dstv403" |
word =="t.co" |
word =="itus" |
word =="rt" |
word =="amp"))
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
library(vader)
library(topicmodels)
library(quanteda)
library(lubridate)
library(zoo)
library(plotly)
vader_df <- vader_df(media_agency_df$text)
vader_df <- vader_df %>% mutate("X1" = row_number())
media_vader_df <- media_agency_df %>% left_join(vader_df, by = "X1")
media_vader_df %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_line(aes(y = pos_daily, colour = "Positive")) +
geom_line(aes(y = neg_daily, colour = "Negative"))
media_vader_df %>% filter(compound != 0)%>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu))
media_vader_df %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_line(aes(y = pos_daily, colour = "Positive")) +
geom_line(aes(y = neg_daily, colour = "Negative"))
media_vader_df %>% filter(compound != 0)%>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_line(aes(y = pos_daily, colour = "Positive")) +
geom_line(aes(y = neg_daily, colour = "Negative"))
media_vader_df %>% filter(compound != 0)%>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_line(aes(y = pos_daily, colour = "Positive")) +
geom_line(aes(y = neg_daily, colour = "Negative"))
media_vader_df %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_line(aes(y = pos_daily, colour = "Positive")) +
geom_line(aes(y = neg_daily, colour = "Negative"))
media_vader_df %>% filter(compound != 0)%>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu))
#JUST tidy
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("enca", "", text),
text = gsub("dstv", "", text),
text = gsub("sabcnews", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," ")) %>%
filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE)))
#JUST tidy
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("enca", "", text),
text = gsub("dstv", "", text),
text = gsub("sabcnews", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," ")) %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE)))
#tidy df and unnest
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="sabcnews" |
word =="enca" |
word =="https" |
word =="dstv" |
word =="sabckzn" |
word =="anc" |
word =="south" |
word =="africa" |
word =="dstv403" |
word =="t.co" |
word =="itus" |
word =="rt" |
word =="amp"))
#JUST tidy
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("enca", "", text),
text = gsub("dstv", "", text),
text = gsub("sabcnews", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," ")) %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE)))
#tidy df and unnest
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="sabcnews" |
word =="enca" |
word =="https" |
word =="dstv" |
word =="sabckzn" |
word =="anc" |
word =="south" |
word =="africa" |
word =="dstv403" |
word =="t.co" |
word =="itus" |
word =="rt" |
word =="amp"))
#JUST tidy
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("enca", "", text),
text = gsub("dstv", "", text),
text = gsub("sabcnews", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," "))
#tidy df and unnest
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="sabcnews" |
word =="enca" |
word =="https" |
word =="dstv" |
word =="sabckzn" |
word =="anc" |
word =="south" |
word =="africa" |
word =="dstv403" |
word =="t.co" |
word =="itus" |
word =="rt" |
word =="amp"))
vader_df <- read_csv("data_in/vader_df.csv")
vader_df <- vader_df %>% mutate("X1" = row_number())
media_vader_df <- media_agency_df %>% left_join(vader_df, by = "X1")
media_vader_df %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_line(aes(y = pos_daily, colour = "Positive")) +
geom_line(aes(y = neg_daily, colour = "Negative"))
media_vader_df <- media_agency_df %>% left_join(vader_df, by = "X1")
#JUST tidy
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("enca", "", text),
text = gsub("dstv", "", text),
text = gsub("sabcnews", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," "))
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
#JUST tidy
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("enca", "", text),
text = gsub("dstv", "", text),
text = gsub("sabcnews", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," "))
#tidy df and unnest
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="sabcnews" |
word =="enca" |
word =="https" |
word =="dstv" |
word =="sabckzn" |
word =="anc" |
word =="south" |
word =="africa" |
word =="dstv403" |
word =="t.co" |
word =="itus" |
word =="rt" |
word =="amp"))
vader_df <- read_csv("data_in/vader_df.csv")
vader_df <- vader_df %>% mutate("X1" = row_number())
media_vader_df <- media_agency_df %>% left_join(vader_df, by = "X1")
media_vader_df %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_line(aes(y = pos_daily, colour = "Positive")) +
geom_line(aes(y = neg_daily, colour = "Negative"))
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_line(aes(y = pos_daily, colour = "Positive")) +
geom_line(aes(y = neg_daily, colour = "Negative"))
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth()
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(y = compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(y = compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(y = media_vader_df$compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = media_vader_df$compound_daily, colour = "Compound")) +
geom_smooth(y = media_vader_df$compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = media_vader_df$compound_daily, colour = "Compound")) +
geom_smooth(y = media_vader_df$compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(aes(y = compound_daily))
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(aes(y = compound_daily), formula = 'y ~ x')
?geom_smooth
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(aes(y = compound_daily), formula = y ~ x)
library(twitterR)
library(twitteR)
origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)
api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
app = "KyleResearchApp",
consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_secret
)
twitteR::userTimeline("News24", n = 100)
origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)
api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
app = "KyleResearchApp",
consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_secret
)
twitteR::userTimeline("News24", n = 100)
?twitteR
??twitteR
library(rtweet)
library(twitteR)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
library(vader)
library(topicmodels)
library(quanteda)
library(lubridate)
library(zoo)
library(plotly)
#sentiment
ggplot(data=media_vader_df, aes(x=created_at, y=rollmean(compound, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(aes(y = compound_daily), formula = y ~ x)
#sentiment
ggplot(data=media_vader_df, aes(x=created_at, fill = screen_name)) +
stat_smooth(media_vader_df %>% filter(screen_name == "News24"), mapping =  aes(y = mean(compound)))+
stat_smooth(media_vader_df %>% filter(screen_name == "ewnupdates"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "eNCA"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "SABCNews"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "TimesLIVE"), mapping =  aes(y = compound))+
theme_minimal()+
scale_y_continuous(expand = c(0,0), breaks = c(-0.1, 0))
#sentiment
ggplot(data=media_vader_df, aes(x=created_at, fill = screen_name)) +
stat_smooth(media_vader_df %>% filter(screen_name == "News24"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "ewnupdates"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "eNCA"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "SABCNews"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "TimesLIVE"), mapping =  aes(y = compound))+
theme_minimal()+
scale_y_continuous(expand = c(0,0), breaks = c(-0.1, 0))
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("mailandguardian", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLive", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)
api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
app = "KyleResearchApp",
consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_secret
)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("mailandguardian", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLive", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("mailandguardian", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("dailymaverick", n = 3200)))
View(media_agency_df)
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("dailymaverick", n = 3200)))
View(media_agency_df)
media_agency_df <- get_timeline("News24", n = 3200)
View(media_agency_df)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
View(media_agency_df)
