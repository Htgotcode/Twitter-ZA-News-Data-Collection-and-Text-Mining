group_by(screen_name) %>%
summarize(total = sum(n))
total_words <- tidy_media_tweets_df %>%
group_by(screen_name) %>%
summarize(total = sum(words))
total_words <- tidy_media_tweets_df %>%
group_by(screen_name) %>%
summarize(total = sum(n))
tidy_media_tweets_df <- media_tweets_df %>%
select(screen_name, status_id, text) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
count(screen_name, word, sort = TRUE)
total_words <- tidy_media_tweets_df %>%
group_by(screen_name) %>%
summarize(total = sum(n))
tidy_media_tweets_df <- left_join(tidy_media_tweets_df, total_words)
View(tidy_media_tweets_df)
ggplot(tidy_media_tweets_df, aes(n/total, fill = screen_name)) +
geom_histogram(show.legend = FALSE) +
xlim(NA, 0.0009) +
facet_wrap(~screen_name, ncol = 2, scales = "free_y")
media_tf <- tidy_media_tweets_df %>%
bind_tf_idf(word, screen_name, n)
View(media_tf)
install.packages("forcats")
media_tf %>%
group_by(screen_name) %>%
slice_max(media_tf, n = 15) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
media_tf %>%
group_by(screen_name) %>%
slice_max(media_tf, n = 15) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = screen_name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
View(media_tf)
library(forcats)
media_tf %>%
group_by(screen_name) %>%
slice_max(media_tf, n = 15) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = screen_name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
media_tf %>%
group_by(screen_name) %>%
slice_max(media_tf, n = 15) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = screen_name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
media_agency_df <- read.csv("data_in/media_agency_tweets")
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
View(media_agency_df)
View(media_agency_df)
View(media_agency_df)
View(media_agency_df)
mutate(created_at = as.POSIXct(created_at, origin = "1970-01-01")
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = as.POSIXct(created_at, origin = "1970-01-01"))
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = as.POSIXct(created_at, origin = "1970-01-01"))
View(media_agency_df)
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = ymd_hms(as.POSIXct(created_at, origin = "1970-01-01")))
library(lubridate
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = ymd_hms(as.POSIXct(created_at, origin = "1970-01-01")))
library(readr)
library(lubridate)
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = ymd_hms(as.POSIXct(created_at, origin = "1970-01-01")))
View(media_agency_df)
ggplot(tweets, aes(x = created_at, fill = screen_name)) +
geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 1)
ggplot(media_agency_df, aes(x = created_at, fill = screen_name)) +
geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 1)
remove_reg <- "&amp;|&lt;|&gt;"
tidy_media_agency_df <- media_agency_df %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
View(tidy_media_agency_df)
media_agency_df <- read_csv("data_in/media_agency_tweets") %>%
mutate(created_at = ymd_hms(as.POSIXct(created_at, origin = "1970-01-01")))
remove_reg <- "&amp;|&lt;|&gt;"
tidy_media_agency_df <- media_agency_df %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
View(tidy_media_agency_df)
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_tweets %>%
group_by(person) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(person) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(screen_name) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
View(frequency)
tidy_media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(screen_name) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
frequency <- frequency %>%
select(screen_name, word, freq) %>%
pivot_wider(names_from = screen_name, values_from = freq)
View(frequency)
ggplot(frequency, aes(News24, ewnupdates)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
ggplot(frequency, aes(News24, ewnupdates)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
ggplot(frequency, aes(News24, ewnupdates)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
word %in% "covid",
word %in% "coronavirus")
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "covid",
!word %in% "coronavirus")
View(tidy_covid_media_df)
View(media_agency_df)
write_as_csv(media_agency_df, "data_in/media_agency_tweets")
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
View(media_agency_df)
install.packages("vader")
#tidy df
remove_reg <- "&amp;|&lt;|&gt;"
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
#calculate a frequency for each person and word
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(screen_name) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
#plot those frequencies on the x- and y-axes
frequency <- frequency %>%
select(screen_name, word, freq) %>%
pivot_wider(names_from = screen_name, values_from = freq)
#yearly
?vader
library(vader)
?vader_df
vader_df(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
select(user_id, status_id, created_at, screen_name, text)
#tidy df
remove_reg <- "&amp;|&lt;|&gt;"
tidy_covid_media_df <- media_agency_df %>%
select(user_id, status_id, created_at, screen_name, text)
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
#tidy df
remove_reg <- "&amp;|&lt;|&gt;"
tidy_covid_media_df <- media_agency_df %>%
select(user_id, status_id, created_at, screen_name, text)
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
#tidy df
remove_reg <- "&amp;|&lt;|&gt;"
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
#calculate a frequency for each person and word
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(screen_name) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
#plot those frequencies on the x- and y-axes
frequency <- frequency %>%
select(screen_name, word, freq) %>%
pivot_wider(names_from = screen_name, values_from = freq)
#yearly
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets")
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
View(tidy_covid_media_df)
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
#tidy df
remove_reg <- "&amp;|&lt;|&gt;"
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
#calculate a frequency for each person and word
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(screen_name) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
#plot those frequencies on the x- and y-axes
frequency <- frequency %>%
select(screen_name, word, freq) %>%
pivot_wider(names_from = screen_name, values_from = freq)
#yearly
View(tidy_covid_media_df)
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
View(media_agency_df)
remove_reg <- "&amp;|&lt;|&gt;"
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text))
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT"))
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg))
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets")
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus") %>%
anti_join(media_agency_df)
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus") %>%
left_join(media_agency_df)
View(tidy_covid_media_df)
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus") %>%
anti_join(get_stopwords())
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus") %>%
anti_join(get_stopwords())
View(tidy_covid_media_df)
media_agency_df %>%  unnest_tokens(word, text, token = "tweets")
media_agency_df %>%  unnest_tokens(word, text, token = "tweets") %>% anti_join(get_stopwords())
tidy_covid_media_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!word %in% "cov",
!word %in% "coronavirus")
vader_df(tidy_covid_media_df$word)
vader_df <- vader_df(tidy_covid_media_df$word)
View(vader_df)
tidy_covid_media_df %>% left_join(vader_df, by = word)
tidy_covid_media_df %>% left_join(vader_df, by = "word")
tidy_covid_media_df %>% left_join(vader_df, by = `word`)
tidy_covid_media_df %>% left_join(vader_df, by = `word`)
tidy_covid_media_df %>% left_join(vader_df
tidy_covid_media_df %>% left_join(vader_df)
tidy_covid_media_df %>% left_join(vader_df)
vader_df <- rename("word" = text)
vader_df <- vader_df %>% rename("word" = text)
View(vader_df)
tidy_covid_media_df %>% left_join(vader_df)
tidy_covid_media_df %>% left_join(vader_df, by = "word")
tidy_covid_media_df %>% merge(vader_df)
tidy_covid_media_df %>% merge(vader_df, by = "word", all.x = TRUE, allow.cartesian=TRUE)
tidy_covid_media_df %>% left_join(vader_df)
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
library(vader)
tidy_covid_media_df %>% left_join(vader_df)
tidy_covid_media_df <- tidy_covid_media_df %>% left_join(vader_df)
