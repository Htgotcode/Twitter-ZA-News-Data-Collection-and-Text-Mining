facet_wrap(~`screen name`, ncol = 2) +
theme(legend.position="none") +
labs(y = "News24", x = NULL)
ggplot(frequency, aes(x = proportion, y = `News24`,
color = abs(`News24` - proportion))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~`screen name`, ncol = 2) +
theme(legend.position="none") +
labs(y = "News24", x = NULL)
ggplot(frequency, aes(x = proportion, y = `screen name`,
color = proportion)) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~`screen name`, ncol = 2) +
theme(legend.position="none") +
labs(y = "Proportion", x = NULL)
ggplot(frequency, aes(x = proportion, y = `screen name`,
color = proportion)) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~`screen name`, ncol = 2) +
theme(legend.position="none") +
labs(y = "Proportion", x = NULL)
ggplot(frequency, aes(x = proportion, y = word,
color = proportion)) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~`screen name`, ncol = 2) +
theme(legend.position="none") +
labs(y = "Proportion", x = NULL)
```{r fig.height=15}
tidy_news24 <- tweets_news24 %>%
select(screen_name, status_id, text) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
tidy_eNCA <- tweets_eNCA %>%
select(screen_name, status_id, text) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
frequency <- bind_rows(mutate(tidy_news24, screen_name = "News24"),
mutate(tidy_eNCA, screen_name = "eNCA")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(screen_name, word) %>%
group_by(screen_name) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
pivot_wider(names_from = screen_name, values_from = proportion) %>%
pivot_longer(`News24`:`eNCA`,
names_to = "screen name", values_to = "proportion")
ggplot(frequency, aes(x = proportion, y = word,
color = proportion)) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_color_gradient(limits = c(0, 0.001),
low = "darkslategray4", high = "gray75") +
facet_wrap(~`screen name`, ncol = 2) +
theme(legend.position="none") +
labs(y = "Proportion", x = NULL)
---
title: "Assignment 2: Data Collection and Text Mining"
output: bookdown::pdf_document2
---
---
title: "Assignment 2: Data Collection and Text Mining"
output: pdf_book
---
library(bookdown)
library(bookdown)
library(bookdown)
---
title: "Assignment 2: Data Collection and Text Mining"
output: bookdown::pdf_book
---
install.packages(c("cli", "colorspace", "curl", "dplyr", "fansi", "mime", "stringi", "tibble", "xfun"))
install.packages(c("cli", "colorspace", "xfun"))
install.packages(c("cli", "colorspace", "xfun"))
install.packages(c("cli", "colorspace", "xfun"))
install.packages(xfun)
install.packages("xfun")
install.packages("xfun")
install.packages("xfun")
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)
api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
app = "KyleResearchApp",
consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_secret
)
tweets_news24 <- get_timeline(user = "News24", n = 100)
View(tweets_news24)
media_tweets_df <- get_timeline(user = c("News24", "eNCA", "SABC News", "Eyewitness", "Times Live"), n = 3200)
View(media_tweets_df)
media_tweets_df <- get_timeline(user = "News24", n = 3200) #, "eNCA", "SABC News", "Eyewitness", "Times Live"), n = 3200)
View(media_tweets_df)
mutate(rbind(get_timeline(user = "eNCA", n = 3200))
media_tweets_df <- media_tweets_df %>%
media_tweets_df <- media_tweets_df %>%
mutate(rbind(get_timeline(user = "eNCA", n = 3200)))
View(media_tweets_df)
View(media_tweets_df)
View(media_tweets_df)
media_tweets_df <- get_timeline(user = "News24", n = 10) #, "eNCA", "SABC News", "Eyewitness", "Times Live"), n = 3200)
media_tweets_df <- media_tweets_df %>%
mutate(bind_rows(get_timeline(user = "eNCA", n = 10)))
View(media_tweets_df)
media_tweets_df <- media_tweets_df %>%
mutate(inner_join(get_timeline(user = "eNCA", n = 10)))
media_tweets_df <- media_tweets_df %>%
inner_join(get_timeline(user = "eNCA", n = 10))
media_tweets_df <- get_timeline(user = "News24", n = 10) #, "eNCA", "SABC News", "Eyewitness", "Times Live"), n = 3200)
media_tweets_df <- media_tweets_df %>%
inner_join(get_timeline(user = "eNCA", n = 10))
View(media_tweets_df)
media_tweets_df <- get_timeline(user = "News24", n = 10) #, "eNCA", "SABC News", "Eyewitness", "Times Live"), n = 3200)
media_tweets_df2 <- get_timeline(user = "eNCA", n = 10)
media_tweets_df <- media_tweets_df %>%
inner_join(media_tweets_df2)
media_tweets_df <- get_timeline(user = "News24", n = 10) #, "eNCA", "SABC News", "Eyewitness", "Times Live"), n = 3200)
media_tweets_df %>%
inner_join(media_tweets_df2)
media_tweets_df %>%
rbind(media_tweets_df2)
media_tweets_df %>%
rbind(get_timeline(user = "eNCA", n = 10))
media_tweets_df %>%
rbind(get_timeline(user = "eNCA", n = 10)) %>%
rbind(get_timeline(user = "eNCA", n = 10)) %>%
media_tweets_df <- get_timeline(user = "News24", n = 10)
media_tweets_df <- get_timeline(user = "News24", n = 10)
media_tweets_df <- get_timeline(user = "News24", n = 10)
media_tweets_df <- media_tweets_df %>%
rbind(get_timeline(user = "eNCA", n = 10)) %>%
rbind(get_timeline(user = "SABC News", n = 10)) %>%
rbind(get_timeline(user = "Eyewitness", n = 10)) %>%
rbind(get_timeline(user = "Times Live", n = 10))
View(media_tweets_df)
media_tweets_df <- get_timeline(user = "News24", n = 10)
media_tweets_df <- media_tweets_df %>%
rbind(get_timeline(user = "eNCA", n = 10)) %>%
rbind(get_timeline(user = "SABCNews", n = 10)) %>%
rbind(get_timeline(user = "Eyewitness", n = 10)) %>%
rbind(get_timeline(user = "TimesLive", n = 10))
View(media_tweets_df)
media_tweets_df <- get_timeline(user = "News24", n = 180)
media_tweets_df <- media_tweets_df %>%
rbind(get_timeline(user = "eNCA", n = 180)) %>%
rbind(get_timeline(user = "SABCNews", n = 180)) %>%
rbind(get_timeline(user = "Eyewitness", n = 180)) %>%
rbind(get_timeline(user = "TimesLive", n = 180))
View(media_tweets_df)
media_tweets_df <- get_timeline(user = "News24", n = 180) %>%
rbind(get_timeline(user = "eNCA", n = 180)) %>%
rbind(get_timeline(user = "SABCNews", n = 180)) %>%
rbind(get_timeline(user = "Eyewitness", n = 180)) %>%
rbind(get_timeline(user = "TimesLive", n = 180))
media_tweets_df2 <- get_timeline(user = "News24", n = 3200) %>%
rbind(get_timeline(user = "eNCA", n = 3200)) %>%
rbind(get_timeline(user = "SABCNews", n = 3200)) %>%
rbind(get_timeline(user = "Eyewitness", n = 3200)) %>%
rbind(get_timeline(user = "TimesLive", n = 3200))
View(media_tweets_df2)
media_tweets_df2 %>%
count(screen_name)
media_tweets_df <- get_timeline(user = "News24", n = 3200)
media_tweets_df <- media_tweets_df %>%
rbind(get_timeline(user = "News24", n = 3200)) %>%
rbind(get_timeline(user = "eNCA", n = 3200)) %>%
rbind(get_timeline(user = "SABCNews", n = 3200)) %>%
rbind(get_timeline(user = "Eyewitness", n = 3200)) %>%
rbind(get_timeline(user = "TimesLive", n = 3200))
media_tweets_df2 %>%
count(screen_name)
media_tweets_df %>%
count(screen_name)
media_tweets_df <- get_timeline(user = "News24", n = 3200)
media_tweets_df <- media_tweets_df %>%
rbind(get_timeline(user = "eNCA", n = 3200)) %>%
rbind(get_timeline(user = "SABCNews", n = 3200)) %>%
rbind(get_timeline(user = "ewnupdates", n = 3200)) %>%
rbind(get_timeline(user = "TimesLive", n = 3200))
media_tweets_df %>%
count(screen_name)
View(media_tweets_df2)
View(media_tweets_df2)
write.csv(media_tweets_df, file = "media_agency_tweets")
write.csv(x = media_tweets_df, file = "media_agency_tweets")
write.csv(x = media_tweets_df, file = "media_agency_tweets")
media_tweets_df <- apply(media_tweets_df, 2, as.character)
write.csv(x = media_tweets_df, file = "media_agency_tweets")
media_tweets_df <- read.csv("data_in/media_agency_tweets")
View(media_tweets_df)
media_tweets_df <- read.csv("data_in/media_agency_tweets")
tidy_media_tweets_df <- tidy_media_tweets_df %>%
select(screen_name, status_id, text) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
tidy_media_tweets_df <- media_tweets_df %>%
select(screen_name, status_id, text) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
View(tidy_media_tweets_df)
View(tidy_media_tweets_df)
african_media_sentiment <- tidy_media_tweets_df %>%
inner_join(get_sentiments("bing")) %>%
count(screen_name, index = linenumber %/% 80, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative)
View(media_tweets_df)
View(tidy_media_tweets_df)
tidy_media_tweets_df <- media_tweets_df %>%
select(X, screen_name, status_id, text) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
```{r}
african_media_sentiment <- tidy_media_tweets_df %>%
inner_join(get_sentiments("bing")) %>%
count(screen_name, index = row_number() %/% 80, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative)
View(african_media_sentiment)
tidy_media_tweets_df <- media_tweets_df %>%
select(screen_name, status_id, text) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
african_media_sentiment <- tidy_media_tweets_df %>%
inner_join(get_sentiments("bing")) %>%
count(screen_name, index = row_number() %/% 80, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative)
library(ggplot2)
ggplot(african_media_sentiment, aes(index, sentiment, fill = screen_name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 2, scales = "free_x")
ggplot(african_media_sentiment, aes(index, sentiment, fill = screen_name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 5, scales = "free_x")
ggplot(african_media_sentiment, aes(index, sentiment, fill = screen_name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 1, scales = "free_x")
ggplot(african_media_sentiment, aes(index, sentiment, fill = screen_name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 3, scales = "free_x")
african_media_sentiment <- tidy_media_tweets_df %>%
inner_join(get_sentiments("bing")) %>%
count(screen_name, index = row_number() %/% 80, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(african_media_sentiment, aes(index, sentiment, fill = screen_name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 3, scales = "free_x")
african_media_sentiment <- tidy_media_tweets_df %>%
inner_join(get_sentiments("afinn")) %>%
count(screen_name, index = row_number() %/% 80, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative)
library(wordcloud)
install.packages("wordcloud")
library(wordcloud)
library(wordcloud)
tidy_media_tweets_df %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100))
install.packages("reshape2")
library(reshape2)
tidy_media_tweets_df %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"),
max.words = 100)
tidy_media_tweets_df <- media_tweets_df %>%
select(screen_name, status_id, text) %>%
mutate(text = str_replace(text, "</?a(|\s+[^>]+)>", "")) %>%
tidy_media_tweets_df <- media_tweets_df %>%
select(screen_name, status_id, text) %>%
mutate(text = str_replace(text, "(http|ftp|https)://([\w_-]+(?:(?:\.[\w_-]+)+))([\w.,@?^=%&:/~+#-]*[\w@?^=%&/~+#-])?", "")) %>%
tidy_media_tweets_df <- media_tweets_df %>%
select(screen_name, status_id, text) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
View(tidy_media_tweets_df)
View(tidy_media_tweets_df)
tidy_media_tweets_df %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100))
tidy_media_tweets_df %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"),
max.words = 100)
tidy_media_tweets_df %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100))
setwd("~/GitHub/Twitter-ZA-News-Data-Collection-and-Text-Mining")
total_words <- tidy_media_tweets_df %>%
group_by(screen_name) %>%
summarize(total = sum(n))
total_words <- tidy_media_tweets_df %>%
group_by(screen_name) %>%
summarize(total = sum(n))
total_words <- tidy_media_tweets_df %>%
group_by(screen_name) %>%
summarize(total = sum(words))
total_words <- tidy_media_tweets_df %>%
group_by(screen_name) %>%
summarize(total = sum(n))
tidy_media_tweets_df <- media_tweets_df %>%
select(screen_name, status_id, text) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
count(screen_name, word, sort = TRUE)
total_words <- tidy_media_tweets_df %>%
group_by(screen_name) %>%
summarize(total = sum(n))
tidy_media_tweets_df <- left_join(tidy_media_tweets_df, total_words)
View(tidy_media_tweets_df)
ggplot(tidy_media_tweets_df, aes(n/total, fill = screen_name)) +
geom_histogram(show.legend = FALSE) +
xlim(NA, 0.0009) +
facet_wrap(~screen_name, ncol = 2, scales = "free_y")
media_tf <- tidy_media_tweets_df %>%
bind_tf_idf(word, screen_name, n)
View(media_tf)
install.packages("forcats")
media_tf %>%
group_by(screen_name) %>%
slice_max(media_tf, n = 15) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
media_tf %>%
group_by(screen_name) %>%
slice_max(media_tf, n = 15) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = screen_name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
View(media_tf)
library(forcats)
media_tf %>%
group_by(screen_name) %>%
slice_max(media_tf, n = 15) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = screen_name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
media_tf %>%
group_by(screen_name) %>%
slice_max(media_tf, n = 15) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = screen_name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
media_agency_df <- read.csv("data_in/media_agency_tweets")
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
View(media_agency_df)
View(media_agency_df)
View(media_agency_df)
View(media_agency_df)
mutate(created_at = as.POSIXct(created_at, origin = "1970-01-01")
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = as.POSIXct(created_at, origin = "1970-01-01"))
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = as.POSIXct(created_at, origin = "1970-01-01"))
View(media_agency_df)
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = ymd_hms(as.POSIXct(created_at, origin = "1970-01-01")))
library(lubridate
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = ymd_hms(as.POSIXct(created_at, origin = "1970-01-01")))
library(readr)
library(lubridate)
media_agency_df <- read.csv("data_in/media_agency_tweets") %>%
mutate(created_at = ymd_hms(as.POSIXct(created_at, origin = "1970-01-01")))
View(media_agency_df)
ggplot(tweets, aes(x = created_at, fill = screen_name)) +
geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 1)
ggplot(media_agency_df, aes(x = created_at, fill = screen_name)) +
geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +
facet_wrap(~screen_name, ncol = 1)
remove_reg <- "&amp;|&lt;|&gt;"
tidy_media_agency_df <- media_agency_df %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
View(tidy_media_agency_df)
media_agency_df <- read_csv("data_in/media_agency_tweets") %>%
mutate(created_at = ymd_hms(as.POSIXct(created_at, origin = "1970-01-01")))
remove_reg <- "&amp;|&lt;|&gt;"
tidy_media_agency_df <- media_agency_df %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
View(tidy_media_agency_df)
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_tweets %>%
group_by(person) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(person) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(screen_name) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
View(frequency)
tidy_media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = str_remove_all(text, remove_reg)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
frequency <- tidy_media_agency_df %>%
group_by(screen_name) %>%
count(word, sort = TRUE) %>%
left_join(tidy_media_agency_df %>%
group_by(screen_name) %>%
summarise(total = n())) %>%
mutate(freq = n/total)
frequency <- frequency %>%
select(screen_name, word, freq) %>%
pivot_wider(names_from = screen_name, values_from = freq)
View(frequency)
ggplot(frequency, aes(News24, ewnupdates)) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
geom_abline(color = "red")
