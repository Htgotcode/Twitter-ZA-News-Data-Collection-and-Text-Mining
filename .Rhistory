<<<<<<< Updated upstream
<<<<<<< Updated upstream
word =="t.co" |
word =="rt" |
word =="amp"))
View(tidy_covid_media_df)
mytext<- media_agency_df%>%
select(text)
mytext <- get_sentences(mytext)
sr_data <-sentiment(mytext)
#write_csv(sr_data,"data_in/sentimentr_data.csv")
time_data <- media_agency_df %>%
select(X1,created_at,screen_name)
SentiR_data <-left_join(time_data,sr_data,
by=c("X1"="element_id"))
#write_csv(SentiR_data,"data_in/sr_df_time.csv")
#setting the date format
#NB only run date format once
SentiR_data$created_at = ymd_hms(SentiR_data$created_at)
#filtering by news agency
news24<- SentiR_data %>%
filter(screen_name=="News24")
times_live<-SentiR_data %>%
filter(screen_name=="TimesLIVE")
ewn<-SentiR_data %>%
filter(screen_name=="ewnupdates")
sabc<-SentiR_data %>%
filter(screen_name=="SABCNews")
eNCA<-SentiR_data %>%
filter(screen_name=="eNCA")
#graph for News24 sentiment over time
ggplot(data=news24, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title="News24")
#graph for News24 sentiment over time
ggplot(data=times_live, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "Times Live")
#graph for News24 sentiment over time
ggplot(data=ewn, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "EWN")
#qplot(x=created_at, y=sentiment, data=ewn, geom='smooth',span=.5)
#graph for News24 sentiment over time
ggplot(data=eNCA, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "eNCA")
#graph for News24 sentiment over time
ggplot(data=sabc, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "SABC")
tidy_matrix <- tidy_covid_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)
media_lda <- LDA(tidy_matrix, k = 4, control = list(seed = 1234))
media_lda
media_topics <- tidy(media_lda, matrix = "beta")
media_topics
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
#graph for News24 sentiment over time
ggplot(data=news24, aes(x=created_at, y=rollmean(compound, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for News24 sentiment over time
ggplot(data=news24, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for News24 sentiment over time
ggplot(data=times_live, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for EWN sentiment over time
ggplot(data=ewn, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for eNCA sentiment over time
ggplot(data=eNCA, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for SABC sentiment over time
ggplot(data=SABC, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for SABC sentiment over time
ggplot(data=sabc, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
=======
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," "))
mytext<- media_agency_df%>%
select(text)
mytext <- get_sentences(mytext)
sr_data <-sentiment_by(mytext)
>>>>>>> Stashed changes
View(media_agency_df)
sr_data <-sentiment(mytext)
write_csv(sr_data,'sentiment_data.csv')
write_csv(sr_data,'sentimentr_data.csv')
write_csv(sr_data,"data_in/sentimentr_data.csv")
vader_data<- read_csv("data_in/vader_df.csv")
View(vader_data)
View(media_agency_df)
<<<<<<< Updated upstream
=======
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="#sabcnews" |
word =="#enca" |
word =="https" |
word =="#dstv403" |
word =="t.co" |
word =="rt" |
word =="amp"))
tidy_matrix <- tidy_covid_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)
media_lda <- LDA(tidy_matrix, k = 12, control = list(seed = 1234))
media_lda
media_topics <- tidy(media_lda, matrix = "beta")
media_topics
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
media_lda <- LDA(tidy_matrix, k = 6, control = list(seed = 1234))
media_lda
media_topics <- tidy(media_lda, matrix = "beta")
media_topics
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
media_lda <- LDA(tidy_matrix, k = 4, control = list(seed = 1234))
media_lda
media_topics <- tidy(media_lda, matrix = "beta")
media_topics
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
View(vader_data)
mytext<- media_agency_df%>%
select(created_at,text)
View(mytext)
mytext <- get_sentences(mytext$text)
sr_data <-sentiment(mytext)
View(sr_data)
mytext<- media_agency_df%>%
select(text)
mytext <- get_sentences(mytext)
sr_data <-sentiment(mytext)
time_data <- media_agency_df %>%
select(created_at,text)
View(time_data)
SentiR_data <-left_join(time_data,sr_data,
by="text")
time_data <- get_sentences(time_data$text)
SentiR_data <-left_join(time_data,sr_data,
by="text")
SentiR_data <-left_join(time_data,sr_data,
by=c("text"="text")
SentiR_data <-left_join(time_data,sr_data,
SentiR_data <-left_join(time_data,sr_data,
by=c("text","text"))
time_data <- media_agency_df %>%
select(created_at,text)
SentiR_data <-left_join(time_data,sr_data,
by=c("text"="text"))
time_data <- media_agency_df %>%
select(X1,created_at)
SentiR_data <-left_join(time_data,sr_data,
by=c("text"="text"))
View(time_data)
SentiR_data <-left_join(time_data,sr_data,
by=c("X1"="element_id"))
View(SentiR_data)
write_csv(SentiR_data,"data_in/sr_df_time.csv")
#setting the date format
SentiR_data$created_at = ymd_hms(SentiR_data$created_at)
count(sentiment)
View(media_agency_df)
time_data <- media_agency_df %>%
select(X1,created_at,screen_name)
SentiR_data <-left_join(time_data,sr_data,
by=c("X1"="element_id"))
write_csv(SentiR_data,"data_in/sr_df_time.csv")
news24<- SentiR_data %>%
filter(screen_name=="News24")
View(news24)
ggplot(data=news24,
geom_dotplot(mapping=aes(x=created_at,y=setiment)))+
theme_minimal()
#graph for News24 sentiment over time
ggplot(data=news24,
geom_dotplot(aes(x=created_at,y=setiment)))+
theme_minimal()
ggplot(data=news24,aes(x=created_at,y=setiment)+
geom_dotplot())+
theme_minimal()
#graph for News24 sentiment over time
ggplot(data=news24,aes(x=created_at,y=setiment)+
geom_dotplot(aes(color='red')))+
theme_minimal()
ggplot(data=news24, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
theme_minimal()
times_live<-SentiR_data %>%
filter(screen_name=="Times Live")
times_live<-SentiR_data %>%
filter(screen_name=="Times LIVE")
times_live<-SentiR_data %>%
filter(screen_name=="TimesLIVE")
View(times_live)
ewn<-SentiR_data %>%
filter(screen_name=="EWN")
ewn<-SentiR_data %>%
filter(screen_name=="Ewn")
ewn<-SentiR_data %>%
filter(screen_name=="E-WitnessNews")
ewn<-SentiR_data %>%
filter(screen_name=="E-Witness News")
ewn<-SentiR_data %>%
filter(screen_name=="EWitness News")
#graph for News24 sentiment over time
ggplot(data=times_live, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
theme_minimal()
agencies<- media_agency_df %>%
select(screen_name)
agencies %>%
distinct(screen_name)
ewn<-SentiR_data %>%
filter(screen_name=="ewnupdates")
#graph for News24 sentiment over time
ggplot(data=ewn, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
theme_minimal()
sabc<-SentiR_data %>%
filter(screen_name=="SABCNews")
eNCA<-SentiR_data %>%
filter(screen_name=="eNCA")
#graph for News24 sentiment over time
ggplot(data=eNCA, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
theme_minimal()
#graph for News24 sentiment over time
ggplot(data=sabc, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
theme_minimal()
qplot(x=created_at, y=sentiment, data=ewn, geom='smooth',span=.5)
library(zoo)
ggplot(data=ewn, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
geom_line(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()
ggplot(data=ewn, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()
ggplot(data=ewn, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()
#graph for News24 sentiment over time
ggplot(data=news24, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()
#graph for News24 sentiment over time
ggplot(data=times_live, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()
#graph for News24 sentiment over time
ggplot(data=news24, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title="News24")
#graph for News24 sentiment over time
ggplot(data=times_live, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "Times Live")
#graph for News24 sentiment over time
ggplot(data=ewn, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "EWN")
#qplot(x=created_at, y=sentiment, data=ewn, geom='smooth',span=.5)
#graph for News24 sentiment over time
ggplot(data=eNCA, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "eNCA")
#graph for News24 sentiment over time
ggplot(data=sabc, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "SABC")
library(tidytext)
library(tidyverse)
library(textdata)
library(sentimentr)
library(stringr)
library(stringi)
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(scales)
library(readr)
library(lubridate)
library(topicmodels)
library(quanteda)
library(reshape2)
library(zoo)
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
#Cleaning data
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," "))
#tidying data
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="#sabcnews" |
word =="#enca" |
word =="https" |
word =="#dstv403" |
word =="t.co" |
word =="rt" |
word =="amp"))
View(tidy_covid_media_df)
mytext<- media_agency_df%>%
select(text)
mytext <- get_sentences(mytext)
sr_data <-sentiment(mytext)
#write_csv(sr_data,"data_in/sentimentr_data.csv")
time_data <- media_agency_df %>%
select(X1,created_at,screen_name)
SentiR_data <-left_join(time_data,sr_data,
by=c("X1"="element_id"))
#write_csv(SentiR_data,"data_in/sr_df_time.csv")
#setting the date format
#NB only run date format once
SentiR_data$created_at = ymd_hms(SentiR_data$created_at)
#filtering by news agency
news24<- SentiR_data %>%
filter(screen_name=="News24")
times_live<-SentiR_data %>%
filter(screen_name=="TimesLIVE")
ewn<-SentiR_data %>%
filter(screen_name=="ewnupdates")
sabc<-SentiR_data %>%
filter(screen_name=="SABCNews")
eNCA<-SentiR_data %>%
filter(screen_name=="eNCA")
#graph for News24 sentiment over time
ggplot(data=news24, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title="News24")
#graph for News24 sentiment over time
ggplot(data=times_live, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "Times Live")
#graph for News24 sentiment over time
ggplot(data=ewn, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "EWN")
#qplot(x=created_at, y=sentiment, data=ewn, geom='smooth',span=.5)
#graph for News24 sentiment over time
ggplot(data=eNCA, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "eNCA")
#graph for News24 sentiment over time
ggplot(data=sabc, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "SABC")
tidy_matrix <- tidy_covid_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)
media_lda <- LDA(tidy_matrix, k = 4, control = list(seed = 1234))
media_lda
media_topics <- tidy(media_lda, matrix = "beta")
media_topics
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
#graph for News24 sentiment over time
ggplot(data=news24, aes(x=created_at, y=rollmean(compound, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for News24 sentiment over time
ggplot(data=news24, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for News24 sentiment over time
ggplot(data=times_live, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for EWN sentiment over time
ggplot(data=ewn, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for eNCA sentiment over time
ggplot(data=eNCA, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for SABC sentiment over time
ggplot(data=SABC, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for SABC sentiment over time
ggplot(data=sabc, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
View(media_agency_df)
View(media_agency_df)
>>>>>>> Stashed changes
View(media_agency_df)
View(media_agency_df)
dailymaverick<-SentiR_data %>%
filter(screen_name=="dailymaverick")
#finding the screen names of media angencies
agencies<- media_agency_df %>%
select(screen_name)
agencies %>%
distinct(screen_name)
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
#Cleaning data
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," "))
#tidying data
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="#sabcnews" |
word =="#enca" |
word =="https" |
word =="#dstv403" |
word =="t.co" |
word =="rt" |
word =="amp"))
#finding the screen names of media angencies
agencies<- media_agency_df %>%
select(screen_name)
agencies %>%
distinct(screen_name)
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
#Cleaning data
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," "))
#tidying data
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="#sabcnews" |
word =="#enca" |
word =="https" |
word =="#dstv403" |
word =="t.co" |
word =="rt" |
word =="amp"))
<<<<<<< Updated upstream
<<<<<<< Updated upstream
<<<<<<< Updated upstream
vader_df <- read_csv("data_in/vader_df.csv")
vader_df <- vader_df %>% mutate("X1" = row_number())
media_vader_df <- media_agency_df %>% left_join(vader_df, by = "X1")
media_vader_df %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_line(aes(y = pos_daily, colour = "Positive")) +
geom_line(aes(y = neg_daily, colour = "Negative"))
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_line(aes(y = pos_daily, colour = "Positive")) +
geom_line(aes(y = neg_daily, colour = "Negative"))
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth()
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(y = compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(y = compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(y = media_vader_df$compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = media_vader_df$compound_daily, colour = "Compound")) +
geom_smooth(y = media_vader_df$compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = media_vader_df$compound_daily, colour = "Compound")) +
geom_smooth(y = media_vader_df$compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(aes(y = compound_daily))
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(aes(y = compound_daily), formula = 'y ~ x')
?geom_smooth
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(aes(y = compound_daily), formula = y ~ x)
library(twitterR)
library(twitteR)
origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)
api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
app = "KyleResearchApp",
consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_secret
)
twitteR::userTimeline("News24", n = 100)
origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)
api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
app = "KyleResearchApp",
consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_secret
)
twitteR::userTimeline("News24", n = 100)
?twitteR
??twitteR
library(rtweet)
library(twitteR)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
library(vader)
library(topicmodels)
library(quanteda)
library(lubridate)
library(zoo)
library(plotly)
#sentiment
ggplot(data=media_vader_df, aes(x=created_at, y=rollmean(compound, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(aes(y = compound_daily), formula = y ~ x)
#sentiment
ggplot(data=media_vader_df, aes(x=created_at, fill = screen_name)) +
stat_smooth(media_vader_df %>% filter(screen_name == "News24"), mapping =  aes(y = mean(compound)))+
stat_smooth(media_vader_df %>% filter(screen_name == "ewnupdates"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "eNCA"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "SABCNews"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "TimesLIVE"), mapping =  aes(y = compound))+
theme_minimal()+
scale_y_continuous(expand = c(0,0), breaks = c(-0.1, 0))
#sentiment
ggplot(data=media_vader_df, aes(x=created_at, fill = screen_name)) +
stat_smooth(media_vader_df %>% filter(screen_name == "News24"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "ewnupdates"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "eNCA"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "SABCNews"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "TimesLIVE"), mapping =  aes(y = compound))+
theme_minimal()+
scale_y_continuous(expand = c(0,0), breaks = c(-0.1, 0))
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("mailandguardian", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLive", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)
api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
app = "KyleResearchApp",
consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_secret
)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("mailandguardian", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLive", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("mailandguardian", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("dailymaverick", n = 3200)))
View(media_agency_df)
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("dailymaverick", n = 3200)))
View(media_agency_df)
media_agency_df <- get_timeline("News24", n = 3200)
View(media_agency_df)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
View(media_agency_df)
=======
=======
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
#finding the screen names of media angencies
agencies<- media_agency_df %>%
select(screen_name)
agencies %>%
distinct(screen_name)
<<<<<<< Updated upstream
<<<<<<< Updated upstream
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
View(cnnc)
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
install.packages("tidytext")
library(tidytext)
library(tidyverse)
library(textdata)
library(sentimentr)
library(stringr)
library(stringi)
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(scales)
library(readr)
library(lubridate)
library(topicmodels)
library(quanteda)
library(reshape2)
library(zoo)
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
#finding the screen names of media angencies
agencies<- media_agency_df %>%
select(screen_name)
agencies %>%
distinct(screen_name)
#Cleaning data
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," "))
#tidying data
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="#sabcnews" |
word =="#enca" |
word =="https" |
word =="#dstv403" |
word =="t.co" |
word =="rt" |
word =="amp"))
mytext<- media_agency_df%>%
select(text)
mytext <- get_sentences(mytext)
sr_data <-sentiment(mytext)
#write_csv(sr_data,"data_in/sentimentr_data.csv")
time_data <- media_agency_df %>%
select(X1,created_at,screen_name)
View(media_agency_df)
View(media_agency_df)
#Cleaning data
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," "))
#tidying data
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="#sabcnews" |
word =="#enca" |
word =="https" |
word =="#dstv403" |
word =="t.co" |
word =="rt" |
word =="amp"))
=======
>>>>>>> Stashed changes
=======
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE) +
facet_wrap(~screen_name, scales = "free_x") +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "1 week")
?xlab
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE) +
facet_wrap(~screen_name, scales = "free_x") +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "1 week") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 1) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "1 day") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 1) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "1 day") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "1 day") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at) %>%
filter(screen_name == "eNCA") %>%
summarise(compound), aes(created_at, compound)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE) +
theme_minimal()+
scale_y_continuous(expand = c(0,0))
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "1 day") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "1 day", date_labels = "%m-%d") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
media_vader_df$screen_name
count(media_vader_df$screen_name)
media_vader_df %>%  group_by(screen_name) %>%  summarise(n = n())
media_vader_df %>%  group_by(created_at, screen_name) %>%  summarise(n = n())
media_vader_df %>%  group_by(as.Date(created_at), screen_name) %>%  summarise(n = n())
media_vader_df %>%  group_by(as.Date(created_at), screen_name) %>% filter(screen_name == "TimesLIVE") %>% summarise(n = n())
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "1 day", date_labels = "%m-%d") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
group_by(as.Date(created_at), screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "1 day", date_labels = "%m-%d") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
as.Date(created_at)
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "1 day", date_labels = "%m-%d") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE, se = FALSE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "1 day", date_labels = "%m-%d") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE, se = FALSE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "3 day", date_labels = "%m-%d") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound))
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE, se = FALSE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "3 day", date_labels = "%m-%d") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound))
media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(as.double(compound)))
mutate(compound = replace(compound, is.na(compound), 0)%>%
media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
mutate(compound = replace(compound, is.na(compound), 0)) %>%
summarise(sum_compound = sum(as.double(compound)))
media_vader_df %>%
media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
mutate(compound = replace(compound, is.na(compound), 0)) %>%
summarise(sum_compound = sum(as.double(compound)))
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
mutate(compound = replace(compound, is.na(compound), 0)) %>%
summarise(sum_compound = sum(as.double(compound))), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE, se = FALSE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "3 day", date_labels = "%m-%d") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
summarise(sum_compound = sum(compound)), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE, se = FALSE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "3 day", date_labels = "%m-%d") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
mutate(compound = replace(compound, is.na(compound), 0)) %>%
summarise(sum_compound = sum(as.double(compound))), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE, se = FALSE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "3 day", date_labels = "%m-%d") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
#tidy df and unnest
tidy_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% agency_stop_words$word,
!word %in% negated_words$word2,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"))
vader_df <- vader_df(media_agency_df$text)
write_as_csv(vader_df, "data_in/vader")
vader_df <- read_csv("data_in/vader.csv")
vader_df <- vader_df %>% mutate("X1" = row_number())
media_agency_df <- media_agency_df %>% mutate("X1" = row_number())
media_vader_df <- media_agency_df %>% left_join(vader_df, by = "X1")
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
mutate(compound = replace(compound, is.na(compound), 0)) %>%
summarise(sum_compound = sum(as.double(compound))), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE, se = FALSE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "3 day", date_labels = "%m-%d") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
mutate(compound = replace(compound, is.na(compound), 0)) %>%
summarise(sum_compound = sum(as.double(compound))), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE, se = FALSE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "3 day", date_labels = "%m-%d") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
#General sentiment over time. Media agencies seem to have an even number of positive and negative tweets per day.
ggplot(media_vader_df %>%
mutate(created_at = as.Date(created_at)) %>%
group_by(created_at, screen_name) %>%
mutate(compound = replace(compound, is.na(compound), 0)) %>%
summarise(sum_compound = sum(as.double(compound))), aes(created_at, sum_compound, fill = screen_name)) +
geom_bar(stat = "identity")+
geom_smooth(method = "lm", na.rm = TRUE, se = FALSE) +
facet_wrap(~screen_name, scales = "free_x", ncol = 2) +
theme_minimal()+
scale_y_continuous(expand = c(0,0)) +
scale_x_date(date_breaks = "3 day", date_labels = "%m-%d") +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
)
media_agency_section_words <- media_agency_df %>%
mutate(section = row_number() %/% 10) %>%
filter(section > 0) %>%
unnest_tokens(word, text) %>%
filter(!word %in% stop_words$word)
# count words co-occuring within sections
word_pairs <- media_agency_section_words %>%
pairwise_count(word, section, sort = TRUE)
# we need to filter for at least relatively common words first
word_cors <- media_agency_section_words %>%
group_by(word) %>%
filter(n() >= 20) %>%
pairwise_cor(word, section, sort = TRUE)
# Correlation of next word
# word_cors %>%
#   filter(item1 == "vaccine")
word_cors %>%
filter(item1 %in% c("covid", "vaccine", "lockdown", "guateng")) %>%
group_by(item1) %>%
slice_max(correlation, n = 6) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip()
set.seed(1234)
word_cors %>%
filter(correlation > .7) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE, edge_width = 3) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
# count words co-occuring within sections
word_pairs <- tidy_media_df %>%
pairwise_count(word, section, sort = TRUE)
media_agency_section_words <- tidy_media_df %>%
mutate(section = row_number() %/% 10) %>%
filter(section > 0)
media_agency_section_words <- tidy_media_df %>%
mutate(section = row_number() %/% 10) %>%
filter(section > 0)
# count words co-occuring within sections
word_pairs <- media_agency_section_words %>%
pairwise_count(word, section, sort = TRUE)
# we need to filter for at least relatively common words first
word_cors <- media_agency_section_words %>%
group_by(word) %>%
filter(n() >= 20) %>%
pairwise_cor(word, section, sort = TRUE)
# Correlation of next word
# word_cors %>%
#   filter(item1 == "vaccine")
word_cors %>%
filter(item1 %in% c("covid", "vaccine", "lockdown", "guateng")) %>%
group_by(item1) %>%
slice_max(correlation, n = 6) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip()
set.seed(1234)
word_cors %>%
filter(correlation > .7) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE, edge_width = 3) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
word_cors %>%
filter(correlation > .6) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE, edge_width = 3) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
word_cors %>%
filter(correlation > .65) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE, edge_width = 3) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
word_cors %>%
filter(item1 %in% c("covid", "vaccine", "lockdown", "guateng")) %>%
group_by(item1) %>%
slice_max(correlation, n = 6) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip()
word_cors %>%
filter(item1 %in% c("covid", "vaccine", "guateng", "guateng")) %>%
group_by(item1) %>%
slice_max(correlation, n = 6) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip()
lockdown
word_cors %>%
filter(item1 %in% c("covid", "vaccine", "lockdown", "guateng")) %>%
group_by(item1) %>%
slice_max(correlation, n = 6) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip()
View(tidy_media_df)
word_cors %>%
filter(item1 %in% c("covid", "vaccine", "lockdown", "ZUma")) %>%
group_by(item1) %>%
slice_max(correlation, n = 6) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip()
word_cors %>%
filter(item1 %in% c("covid", "vaccine", "lockdown", "zuma")) %>%
group_by(item1) %>%
slice_max(correlation, n = 6) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip()
word_cors %>%
filter(item1 %in% c("covid", "vaccine", "lockdown", "zuma", "gauteng")) %>%
group_by(item1) %>%
slice_max(correlation, n = 6) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip()
word_cors %>%
filter(item1 %in% c("covid", "vaccine", "lockdown", "zuma", "gauteng", "ramaphosa")) %>%
group_by(item1) %>%
slice_max(correlation, n = 6) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip()
>>>>>>> Stashed changes
