<<<<<<< Updated upstream
<<<<<<< Updated upstream
word =="amp"))
#JUST tidy
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("enca", "", text),
text = gsub("dstv", "", text),
text = gsub("sabcnews", "", text),
=======
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
>>>>>>> Stashed changes
=======
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
>>>>>>> Stashed changes
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
<<<<<<< Updated upstream
<<<<<<< Updated upstream
text = str_replace_all(text,"@[a-z,A-Z]*"," ")) %>%
filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE)))
#tidy df and unnest
tidy_covid_media_df <- media_agency_df %>%
filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="sabcnews" |
word =="enca" |
word =="https" |
word =="dstv" |
word =="sabckzn" |
word =="anc" |
word =="south" |
word =="africa" |
word =="dstv403" |
word =="t.co" |
word =="itus" |
word =="rt" |
word =="amp"))
=======
=======
>>>>>>> Stashed changes
text = str_replace_all(text,"@[a-z,A-Z]*"," "))
mytext<- media_agency_df%>%
select(text)
mytext <- get_sentences(mytext)
sr_data <-sentiment_by(mytext)
<<<<<<< Updated upstream
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
View(media_agency_df)
sr_data <-sentiment(mytext)
write_csv(sr_data,'sentiment_data.csv')
write_csv(sr_data,'sentimentr_data.csv')
write_csv(sr_data,"data_in/sentimentr_data.csv")
vader_data<- read_csv("data_in/vader_df.csv")
View(vader_data)
View(media_agency_df)
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="#sabcnews" |
word =="#enca" |
word =="https" |
word =="#dstv403" |
word =="t.co" |
word =="rt" |
word =="amp"))
tidy_matrix <- tidy_covid_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)
media_lda <- LDA(tidy_matrix, k = 12, control = list(seed = 1234))
media_lda
media_topics <- tidy(media_lda, matrix = "beta")
media_topics
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
media_lda <- LDA(tidy_matrix, k = 6, control = list(seed = 1234))
media_lda
media_topics <- tidy(media_lda, matrix = "beta")
media_topics
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
media_lda <- LDA(tidy_matrix, k = 4, control = list(seed = 1234))
media_lda
media_topics <- tidy(media_lda, matrix = "beta")
media_topics
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
View(vader_data)
mytext<- media_agency_df%>%
select(created_at,text)
View(mytext)
mytext <- get_sentences(mytext$text)
sr_data <-sentiment(mytext)
View(sr_data)
mytext<- media_agency_df%>%
select(text)
mytext <- get_sentences(mytext)
sr_data <-sentiment(mytext)
time_data <- media_agency_df %>%
select(created_at,text)
View(time_data)
SentiR_data <-left_join(time_data,sr_data,
by="text")
time_data <- get_sentences(time_data$text)
SentiR_data <-left_join(time_data,sr_data,
by="text")
SentiR_data <-left_join(time_data,sr_data,
by=c("text"="text")
SentiR_data <-left_join(time_data,sr_data,
SentiR_data <-left_join(time_data,sr_data,
by=c("text","text"))
time_data <- media_agency_df %>%
select(created_at,text)
SentiR_data <-left_join(time_data,sr_data,
by=c("text"="text"))
time_data <- media_agency_df %>%
select(X1,created_at)
SentiR_data <-left_join(time_data,sr_data,
by=c("text"="text"))
View(time_data)
SentiR_data <-left_join(time_data,sr_data,
by=c("X1"="element_id"))
View(SentiR_data)
write_csv(SentiR_data,"data_in/sr_df_time.csv")
#setting the date format
SentiR_data$created_at = ymd_hms(SentiR_data$created_at)
count(sentiment)
View(media_agency_df)
time_data <- media_agency_df %>%
select(X1,created_at,screen_name)
SentiR_data <-left_join(time_data,sr_data,
by=c("X1"="element_id"))
write_csv(SentiR_data,"data_in/sr_df_time.csv")
news24<- SentiR_data %>%
filter(screen_name=="News24")
View(news24)
ggplot(data=news24,
geom_dotplot(mapping=aes(x=created_at,y=setiment)))+
theme_minimal()
#graph for News24 sentiment over time
ggplot(data=news24,
geom_dotplot(aes(x=created_at,y=setiment)))+
theme_minimal()
ggplot(data=news24,aes(x=created_at,y=setiment)+
geom_dotplot())+
theme_minimal()
#graph for News24 sentiment over time
ggplot(data=news24,aes(x=created_at,y=setiment)+
geom_dotplot(aes(color='red')))+
theme_minimal()
ggplot(data=news24, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
theme_minimal()
times_live<-SentiR_data %>%
filter(screen_name=="Times Live")
times_live<-SentiR_data %>%
filter(screen_name=="Times LIVE")
times_live<-SentiR_data %>%
filter(screen_name=="TimesLIVE")
View(times_live)
ewn<-SentiR_data %>%
filter(screen_name=="EWN")
ewn<-SentiR_data %>%
filter(screen_name=="Ewn")
ewn<-SentiR_data %>%
filter(screen_name=="E-WitnessNews")
ewn<-SentiR_data %>%
filter(screen_name=="E-Witness News")
ewn<-SentiR_data %>%
filter(screen_name=="EWitness News")
#graph for News24 sentiment over time
ggplot(data=times_live, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
theme_minimal()
agencies<- media_agency_df %>%
select(screen_name)
agencies %>%
distinct(screen_name)
ewn<-SentiR_data %>%
filter(screen_name=="ewnupdates")
#graph for News24 sentiment over time
ggplot(data=ewn, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
theme_minimal()
sabc<-SentiR_data %>%
filter(screen_name=="SABCNews")
eNCA<-SentiR_data %>%
filter(screen_name=="eNCA")
#graph for News24 sentiment over time
ggplot(data=eNCA, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
theme_minimal()
#graph for News24 sentiment over time
ggplot(data=sabc, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
theme_minimal()
qplot(x=created_at, y=sentiment, data=ewn, geom='smooth',span=.5)
library(zoo)
ggplot(data=ewn, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
geom_line(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()
ggplot(data=ewn, aes(x=created_at, y=sentiment))+
geom_line(color="red", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()
ggplot(data=ewn, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()
#graph for News24 sentiment over time
ggplot(data=news24, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()
#graph for News24 sentiment over time
ggplot(data=times_live, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()
#graph for News24 sentiment over time
ggplot(data=news24, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title="News24")
#graph for News24 sentiment over time
ggplot(data=times_live, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "Times Live")
#graph for News24 sentiment over time
ggplot(data=ewn, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "EWN")
#qplot(x=created_at, y=sentiment, data=ewn, geom='smooth',span=.5)
#graph for News24 sentiment over time
ggplot(data=eNCA, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "eNCA")
#graph for News24 sentiment over time
ggplot(data=sabc, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "SABC")
library(tidytext)
library(tidyverse)
library(textdata)
library(sentimentr)
library(stringr)
library(stringi)
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(scales)
library(readr)
library(lubridate)
library(topicmodels)
library(quanteda)
library(reshape2)
library(zoo)
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
#Cleaning data
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," "))
#tidying data
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="#sabcnews" |
word =="#enca" |
word =="https" |
word =="#dstv403" |
word =="t.co" |
word =="rt" |
word =="amp"))
View(tidy_covid_media_df)
mytext<- media_agency_df%>%
select(text)
mytext <- get_sentences(mytext)
sr_data <-sentiment(mytext)
#write_csv(sr_data,"data_in/sentimentr_data.csv")
time_data <- media_agency_df %>%
select(X1,created_at,screen_name)
SentiR_data <-left_join(time_data,sr_data,
by=c("X1"="element_id"))
#write_csv(SentiR_data,"data_in/sr_df_time.csv")
#setting the date format
#NB only run date format once
SentiR_data$created_at = ymd_hms(SentiR_data$created_at)
#filtering by news agency
news24<- SentiR_data %>%
filter(screen_name=="News24")
times_live<-SentiR_data %>%
filter(screen_name=="TimesLIVE")
ewn<-SentiR_data %>%
filter(screen_name=="ewnupdates")
sabc<-SentiR_data %>%
filter(screen_name=="SABCNews")
eNCA<-SentiR_data %>%
filter(screen_name=="eNCA")
#graph for News24 sentiment over time
ggplot(data=news24, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title="News24")
#graph for News24 sentiment over time
ggplot(data=times_live, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "Times Live")
#graph for News24 sentiment over time
ggplot(data=ewn, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "EWN")
#qplot(x=created_at, y=sentiment, data=ewn, geom='smooth',span=.5)
#graph for News24 sentiment over time
ggplot(data=eNCA, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "eNCA")
#graph for News24 sentiment over time
ggplot(data=sabc, aes(x=created_at, y=sentiment))+
geom_line(color="pink", size=.5)+
geom_smooth(aes(y=rollmean(sentiment,7,  na.pad=TRUE))) +
theme_minimal()+
labs(title = "SABC")
tidy_matrix <- tidy_covid_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)
media_lda <- LDA(tidy_matrix, k = 4, control = list(seed = 1234))
media_lda
media_topics <- tidy(media_lda, matrix = "beta")
media_topics
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
#graph for News24 sentiment over time
ggplot(data=news24, aes(x=created_at, y=rollmean(compound, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for News24 sentiment over time
ggplot(data=news24, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for News24 sentiment over time
ggplot(data=times_live, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for EWN sentiment over time
ggplot(data=ewn, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for eNCA sentiment over time
ggplot(data=eNCA, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for SABC sentiment over time
ggplot(data=SABC, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
#graph for SABC sentiment over time
ggplot(data=sabc, aes(x=created_at, y=rollmean(sentiment, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
View(media_agency_df)
View(media_agency_df)
View(media_agency_df)
View(media_agency_df)
dailymaverick<-SentiR_data %>%
filter(screen_name=="dailymaverick")
#finding the screen names of media angencies
agencies<- media_agency_df %>%
select(screen_name)
agencies %>%
distinct(screen_name)
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
#Cleaning data
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," "))
#tidying data
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="#sabcnews" |
word =="#enca" |
word =="https" |
word =="#dstv403" |
word =="t.co" |
word =="rt" |
word =="amp"))
#finding the screen names of media angencies
agencies<- media_agency_df %>%
select(screen_name)
agencies %>%
distinct(screen_name)
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
#Cleaning data
media_agency_df <- media_agency_df %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
text = gsub("&amp", "", text),
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
text = gsub("@\\w+", "", text),
text = gsub("[[:punct:]]", "", text),
text = gsub("[[:digit:]]", "", text),
text = gsub("http\\w+", "", text),
text = gsub("[ \t]{2,}", "", text),
text = gsub("^\\s+|\\s+$", "", text),
text = gsub("&amp", "", text)) %>%
mutate(text = str_replace_all(text," "," "),
text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
text = str_replace_all(text,"#[a-z,A-Z]*"," "),
text = str_replace_all(text,"@[a-z,A-Z]*"," "))
#tidying data
tidy_covid_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
filter(!str_detect(text, "^RT")) %>%
mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(!word %in% stop_words$word,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]"),
!(word =="#sabcnews" |
word =="#enca" |
word =="https" |
word =="#dstv403" |
word =="t.co" |
word =="rt" |
word =="amp"))
<<<<<<< Updated upstream
<<<<<<< Updated upstream
vader_df <- read_csv("data_in/vader_df.csv")
vader_df <- vader_df %>% mutate("X1" = row_number())
media_vader_df <- media_agency_df %>% left_join(vader_df, by = "X1")
media_vader_df %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_line(aes(y = pos_daily, colour = "Positive")) +
geom_line(aes(y = neg_daily, colour = "Negative"))
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_line(aes(y = pos_daily, colour = "Positive")) +
geom_line(aes(y = neg_daily, colour = "Negative"))
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth()
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(y = compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(y = compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(y = media_vader_df$compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = media_vader_df$compound_daily, colour = "Compound")) +
geom_smooth(y = media_vader_df$compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = media_vader_df$compound_daily, colour = "Compound")) +
geom_smooth(y = media_vader_df$compound_daily)
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(aes(y = compound_daily))
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(aes(y = compound_daily), formula = 'y ~ x')
?geom_smooth
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(aes(y = compound_daily), formula = y ~ x)
library(twitterR)
library(twitteR)
origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)
api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
app = "KyleResearchApp",
consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_secret
)
twitteR::userTimeline("News24", n = 100)
origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)
api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
app = "KyleResearchApp",
consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_secret
)
twitteR::userTimeline("News24", n = 100)
?twitteR
??twitteR
library(rtweet)
library(twitteR)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
library(vader)
library(topicmodels)
library(quanteda)
library(lubridate)
library(zoo)
library(plotly)
#sentiment
ggplot(data=media_vader_df, aes(x=created_at, y=rollmean(compound, 30,  na.pad=TRUE))) +
geom_line(color="pink", size=.5)+
geom_smooth() +
theme_minimal()+
facet_wrap(~screen_name) +
scale_y_continuous(expand = c(0,0), breaks = c(-0.4,-0.2,0,0.2,0.4)) +
ylim(c(-0.4, 0.4))
media_vader_df %>% filter(compound != 0) %>% mutate(created_at = as.Date(created_at)) %>%  group_by(created_at) %>% mutate(compound_daily = mean(compound), pos_daily = mean(pos), neg_daily = mean(neg), neu_daily = mean(neu)) %>%
ggplot(aes(created_at)) +
geom_line(aes(y = compound_daily, colour = "Compound")) +
geom_smooth(aes(y = compound_daily), formula = y ~ x)
#sentiment
ggplot(data=media_vader_df, aes(x=created_at, fill = screen_name)) +
stat_smooth(media_vader_df %>% filter(screen_name == "News24"), mapping =  aes(y = mean(compound)))+
stat_smooth(media_vader_df %>% filter(screen_name == "ewnupdates"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "eNCA"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "SABCNews"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "TimesLIVE"), mapping =  aes(y = compound))+
theme_minimal()+
scale_y_continuous(expand = c(0,0), breaks = c(-0.1, 0))
#sentiment
ggplot(data=media_vader_df, aes(x=created_at, fill = screen_name)) +
stat_smooth(media_vader_df %>% filter(screen_name == "News24"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "ewnupdates"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "eNCA"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "SABCNews"), mapping =  aes(y = compound))+
stat_smooth(media_vader_df %>% filter(screen_name == "TimesLIVE"), mapping =  aes(y = compound))+
theme_minimal()+
scale_y_continuous(expand = c(0,0), breaks = c(-0.1, 0))
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("mailandguardian", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLive", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)
api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
app = "KyleResearchApp",
consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_secret
)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("mailandguardian", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLive", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("mailandguardian", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("dailymaverick", n = 3200)))
View(media_agency_df)
media_agency_df <- get_timeline("News24", n = 3200)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("dailymaverick", n = 3200)))
View(media_agency_df)
media_agency_df <- get_timeline("News24", n = 3200)
View(media_agency_df)
media_agency_df <- media_agency_df %>%
mutate(rbind(rtweet::get_timeline("eNCA", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("TimesLIVE", n = 3200))) %>%
mutate(rbind(rtweet::get_timeline("SABCNews", n = 3200)))
View(media_agency_df)
=======
=======
>>>>>>> Stashed changes
#finding the screen names of media angencies
agencies<- media_agency_df %>%
select(screen_name)
agencies %>%
distinct(screen_name)
<<<<<<< Updated upstream
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
