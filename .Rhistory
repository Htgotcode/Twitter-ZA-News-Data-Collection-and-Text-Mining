"orld",
"sunday",
"friday",
"saturday",
"thursday",
"pics"
)
)
#created if more tweets could be accessed to be more topic specific
# covid_dictionary <- c("herd", "immunity", "incubation", "job", "loss", "Kits", "lockdown", "mask", "N95", "outbreak", "pandemic", "quarantine", "recovery", "sanitiser", "transmission", "Underlying", "conditions", "Ventilators", "WHO", "xenophobia", "youTube", "zoonotic", "stay-at-home", "covid", "coronavirus", "hyrdoxychloroquine", "asymptomatic", "frontline", "virus", "self-isolation", "disinfectant", "shelter-in-place", "masks", "SARS-CoV-2", "ICU", "corona", "reopen", "distancing", "covering", "furlough", "tracer", "easing", "remdesivir", "mail-in", "hornet", "antibody", "in-person", "defund", "racism", "looting", "loot", "reopen", "two-metre", "pandemic", "looter", "distancing", "dexamethasone", "racial", "vaccine", "curfew","johnssons", "astrazeneca", "hospitals", "social-distance", "social-distancing", "police", "regulations", "symptoms", "testing", "positive-tests", "negative-tests" , "confirmed-cases", "restrictions", "deaths", "infected", "recoveries", "level", "jobs", "unemployed", "doctors", "infections", "sanitise", "sanitiser", "sanitisation", "containment")
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
media_agency_df <-
media_agency_df[, colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
#JUST tidy
rm_twitter_n_url <-
rm_(pattern = pastex("@rm_twitter_url", "@rm_url"))
media_agency_df <- media_agency_df %>%
mutate(
text = rm_twitter_n_url(text),
text = gsub("@\\w+", " ", text),
text = gsub("[[:punct:]]", " ", text),
text = gsub("[[:digit:]]", " ", text),
text = gsub("http\\w+", " ", text),
text = gsub("[ |\t]{2,}", " ", text),
text = gsub("^ ", " ", text),
text = gsub(" $", " ", text),
text = gsub("^(*business*)", "", text),
text = gsub("^(*BUSINESS*)", "", text),
text = gsub("^(*world*)", "", text),
text = gsub("^(*WORLD*)", "", text)
) %>%
mutate(
text = str_replace_all(text, " ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " "),
text = str_replace_all(text, " ", " "),
text = str_replace_all(text, "RT @[a-z,A-Z]*: ", " "),
text = str_replace_all(text, "#[a-z,A-Z]*", " "),
text = str_replace_all(text, "@[a-z,A-Z]*", " ")
)
#most stop words are filtered based on the media agencies tag at the beginning of each Tweet. eg. WATCH: *headline follows*.
agency_stop_words <-
tibble(
word = c(
"sabcnews",
"enca",
"dstv",
"sabckzn",
"maverick",
"opinionista",
"dm",
"scorpio",
"dstv403",
"itus",
"rt",
"amp",
"tgifood",
"mamelodi",
"sundowns",
"ofmagazineavailable",
"casablanca",
"oped",
"newsdeck",
"editorial",
"newflash",
"southafricanmorning",
"newslink",
"encas",
"southafricatonight",
"themiddayview",
"thelead",
"propertymatters",
"ba",
"ka",
"ya",
"ga",
"wa",
"le",
"kwa",
"morninglivesabc",
"monday",
"prix",
"azerbaijan",
"encasis",
"encabusiness",
"encasspeaks",
"south",
"africa",
"pm",
"sa",
"pm",
"encas",
"iss",
"icymi",
"timeslive",
"fullview",
"newsbreaksjul",
"newsbreakjul",
"sabc",
"nca",
"ncas",
"op",
"ig",
"ed",
"pl",
"news24",
"news24s",
"dm168",
"siness",
"usiness",
"ewsdeck",
"orld",
"sunday",
"friday",
"saturday",
"thursday",
"pics"
)
)
#tidy df and unnest
tidy_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(
!word %in% stop_words$word,!word %in% agency_stop_words$word,
!word %in% negated_words$word2,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]")
)
tidy_matrix <-
tidy_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)
media_lda <- LDA(tidy_matrix, k = 5, control = list(seed = 1234))
media_topics <- tidy(media_lda, matrix = "beta")
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic,-beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
pivot_wider(id_cols = term,
names_from = topic,
values_from = beta) %>%
rename(
"s" = 2,
"Nations Address" = 3,
"Covid World News" = 4,
"Former President Zuma facing court" = 5,
"Vaccination distributions" = 6
) %>%
pivot_longer(cols = c(2, 3, 4, 5, 6),
names_to = "topic",
values_to = "beta") %>%
drop_na() %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap( ~ topic, scales = "free") +
scale_y_reordered()
#created if more tweets could be accessed to be more topic specific
# covid_dictionary <- c("herd", "immunity", "incubation", "job", "loss", "Kits", "lockdown", "mask", "N95", "outbreak", "pandemic", "quarantine", "recovery", "sanitiser", "transmission", "Underlying", "conditions", "Ventilators", "WHO", "xenophobia", "youTube", "zoonotic", "stay-at-home", "covid", "coronavirus", "hyrdoxychloroquine", "asymptomatic", "frontline", "virus", "self-isolation", "disinfectant", "shelter-in-place", "masks", "SARS-CoV-2", "ICU", "corona", "reopen", "distancing", "covering", "furlough", "tracer", "easing", "remdesivir", "mail-in", "hornet", "antibody", "in-person", "defund", "racism", "looting", "loot", "reopen", "two-metre", "pandemic", "looter", "distancing", "dexamethasone", "racial", "vaccine", "curfew","johnssons", "astrazeneca", "hospitals", "social-distance", "social-distancing", "police", "regulations", "symptoms", "testing", "positive-tests", "negative-tests" , "confirmed-cases", "restrictions", "deaths", "infected", "recoveries", "level", "jobs", "unemployed", "doctors", "infections", "sanitise", "sanitiser", "sanitisation", "containment")
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
media_agency_df <-
media_agency_df[, colSums(is.na(media_agency_df)) < nrow(media_agency_df)]
#JUST tidy
rm_twitter_n_url <-
rm_(pattern = pastex("@rm_twitter_url", "@rm_url"))
media_agency_df <- media_agency_df %>%
mutate(
text = rm_twitter_n_url(text),
text = gsub("@\\w+", " ", text),
text = gsub("[[:punct:]]", " ", text),
text = gsub("[[:digit:]]", " ", text),
text = gsub("http\\w+", " ", text),
text = gsub("[ |\t]{2,}", " ", text),
text = gsub("^ ", " ", text),
text = gsub(" $", " ", text),
text = gsub("^(*business*)", "", text),
text = gsub("^(*BUSINESS*)", "", text),
text = gsub("^(*world*)", "", text),
text = gsub("^(*WORLD*)", "", text)
) %>%
mutate(
text = str_replace_all(text, " ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " "),
text = str_replace_all(text, " ", " "),
text = str_replace_all(text, "RT @[a-z,A-Z]*: ", " "),
text = str_replace_all(text, "#[a-z,A-Z]*", " "),
text = str_replace_all(text, "@[a-z,A-Z]*", " ")
)
#most stop words are filtered based on the media agencies tag at the beginning of each Tweet. eg. WATCH: *headline follows*.
agency_stop_words <-
tibble(
word = c(
"sabcnews",
"enca",
"dstv",
"sabckzn",
"maverick",
"opinionista",
"dm",
"scorpio",
"dstv403",
"itus",
"rt",
"amp",
"tgifood",
"mamelodi",
"sundowns",
"ofmagazineavailable",
"casablanca",
"oped",
"newsdeck",
"editorial",
"newflash",
"southafricanmorning",
"newslink",
"encas",
"southafricatonight",
"themiddayview",
"thelead",
"propertymatters",
"ba",
"ka",
"ya",
"ga",
"wa",
"le",
"kwa",
"morninglivesabc",
"monday",
"prix",
"azerbaijan",
"encasis",
"encabusiness",
"encasspeaks",
"south",
"africa",
"pm",
"sa",
"pm",
"encas",
"iss",
"icymi",
"timeslive",
"fullview",
"newsbreaksjul",
"newsbreakjul",
"sabc",
"nca",
"ncas",
"op",
"ig",
"ed",
"pl",
"news24",
"news24s",
"dm168",
"siness",
"usiness",
"ewsdeck",
"orld",
"sunday",
"friday",
"saturday",
"thursday",
"wednesday",
"monday",
"tuesday",
"pics"
)
)
#tidy df and unnest
tidy_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(
!word %in% stop_words$word,!word %in% agency_stop_words$word,
!word %in% negated_words$word2,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]")
)
tidy_matrix <-
tidy_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)
media_lda <- LDA(tidy_matrix, k = 5, control = list(seed = 1234))
media_topics <- tidy(media_lda, matrix = "beta")
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic,-beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
pivot_wider(id_cols = term,
names_from = topic,
values_from = beta) %>%
rename(
"s" = 2,
"Nations Address" = 3,
"Covid World News" = 4,
"Former President Zuma facing court" = 5,
"Vaccination distributions" = 6
) %>%
pivot_longer(cols = c(2, 3, 4, 5, 6),
names_to = "topic",
values_to = "beta") %>%
drop_na() %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap( ~ topic, scales = "free") +
scale_y_reordered()
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
pivot_wider(id_cols = term,
names_from = topic,
values_from = beta) %>%
rename(
"Covid & Business World News" = 2,
"Former President Zuma facing court" = 3,
"Nations Address" = 4,
"" = 5,
"Minister News" = 6
) %>%
pivot_longer(cols = c(2, 3, 4, 5, 6),
names_to = "topic",
values_to = "beta") %>%
drop_na() %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap( ~ topic, scales = "free") +
scale_y_reordered()
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
pivot_wider(id_cols = term,
names_from = topic,
values_from = beta) %>%
rename(
"Covid & Business World News" = 2,
"Former President Zuma facing court" = 3,
"Nations Address" = 4,
" " = 5,
"Minister News" = 6
) %>%
pivot_longer(cols = c(2, 3, 4, 5, 6),
names_to = "topic",
values_to = "beta") %>%
drop_na() %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap( ~ topic, scales = "free") +
scale_y_reordered()
#most stop words are filtered based on the media agencies tag at the beginning of each Tweet. eg. WATCH: *headline follows*.
agency_stop_words <-
tibble(
word = c(
"sabcnews",
"enca",
"dstv",
"sabckzn",
"maverick",
"opinionista",
"dm",
"scorpio",
"dstv403",
"itus",
"rt",
"amp",
"tgifood",
"mamelodi",
"sundowns",
"ofmagazineavailable",
"casablanca",
"oped",
"newsdeck",
"editorial",
"newflash",
"southafricanmorning",
"newslink",
"encas",
"southafricatonight",
"themiddayview",
"thelead",
"propertymatters",
"ba",
"ka",
"ya",
"ga",
"wa",
"le",
"kwa",
"morninglivesabc",
"monday",
"prix",
"azerbaijan",
"encasis",
"encabusiness",
"encasspeaks",
"south",
"africa",
"pm",
"sa",
"pm",
"encas",
"iss",
"icymi",
"timeslive",
"fullview",
"newsbreaksjul",
"newsbreakjul",
"sabc",
"nca",
"ncas",
"op",
"ig",
"ed",
"pl",
"news24",
"news24s",
"dm168",
"siness",
"usiness",
"ewsdeck",
"orld",
"sunday",
"friday",
"saturday",
"thursday",
"wednesday",
"monday",
"tuesday",
"pics",
"live"
)
)
#tidy df and unnest
tidy_media_df <- media_agency_df %>%
#filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
unnest_tokens(word, text, token = "tweets") %>%
filter(
!word %in% stop_words$word,!word %in% agency_stop_words$word,
!word %in% negated_words$word2,
!word %in% str_remove_all(stop_words$word, "'"),
str_detect(word, "[a-z]")
)
tidy_matrix <-
tidy_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)
media_lda <- LDA(tidy_matrix, k = 5, control = list(seed = 1234))
media_topics <- tidy(media_lda, matrix = "beta")
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic,-beta)
media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
pivot_wider(id_cols = term,
names_from = topic,
values_from = beta) %>%
rename(
"Covid & Business World News" = 2,
"Former President Zuma facing court" = 3,
"Nations Address" = 4,
" " = 5,
"Minister News" = 6
) %>%
pivot_longer(cols = c(2, 3, 4, 5, 6),
names_to = "topic",
values_to = "beta") %>%
drop_na() %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap( ~ topic, scales = "free") +
scale_y_reordered()
cvd<- getPage("COVID-19-Information-Center", fb_oauth, n=5000)
install.packages("Rfacebook")
library(Rfacebook)
fb_oauth <-
fbOAuth(app_id = "3010431072611630", app_secret = "c2e7a40bc573bc2906632addc2c11740")
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidytext)
library(stringr)
library(scales)
library(readr)
library(lubridate)
library(vader)
library(topicmodels)
library(quanteda)
library(lubridate)
library(zoo)
library(plotly)
library(forcats)
library(igraph)
library(ggraph)
library(widyr)
library(qdapRegex)
library(magick)
#Twitter API setup
origop <- options("httr_oauth_cache")
options(httr_oauth_cache = TRUE)
api_key <- "5PgtS7ljq5ZbBoXnemU5qHe62"
api_secret <- "M44LeduQ4zoyDxQIkAFjeIJrpDhWnb5xASDvhahTlrAvOhN7fx"
access_token <- "743029724750942208-JLEp26XrjwvQ1CPJUXwvdUMLka82cgx"
access_secret <- "XRMeMBaOgQy2BC1Bd9iJARfMIyK40VKyII1ZRcf9nS0qd"
token <- create_token(
app = "KyleResearchApp",
consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_secret
)
library(Rfacebook)
fb_oauth <-
fbOAuth(app_id = "3010431072611630", app_secret = "c2e7a40bc573bc2906632addc2c11740")
