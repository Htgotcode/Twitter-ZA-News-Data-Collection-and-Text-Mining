---
title: "R Notebook"
output: html_notebook
---
Reasons for the media sources chosen:
News 24 : Recognized by APP Annie (App Annie is the standard in app analytics and app market data) as the most known South African internet media source. (Chinese Academy of Cyberspace Studiespublisher=Springer (15 September 2018). World Internet Development Report 2017: Translated by Peng Ping. p. 203. ISBN 9783662575246. OCLC 1052766508.)

Times Live : South Africa's second-biggest news website, published by Arena Holdings (Times Live website)

EWN : Not much info but it can be considered to be popular because it originated from 2 radio stations (KFM and CapeTalk)

eNCA: Not much info but seems popular. Used to E News from TV channel. Might not be as trustworthy as there has been complaints about racism recently.

SABC: National news company with government ties. reaches a wide variety of viewers in different languages.

Justify why we use these agencies. Size? Reputable? unbias?



Importing Packages
```{r}
install.packages("tidytext")
install.packages("tidyverse")
install.packages("sentimentr")
install.packages("textdata")
install.packages("stringi")
install.packages("rtweet")
install.packages("quanteda")
install.packages("topicmodels")
install.packages("reshape2")
```

Importing Libraries
```{r}
library(tidytext)
library(tidyverse)
library(textdata)
library(sentimentr)
library(stringr)
library(stringi)
library(rtweet)
library(ggplot2)
library(tidyr)
library(dplyr)
library(scales)
library(readr)
library(lubridate)
library(topicmodels)
library(quanteda)
library(reshape2)
```
Importing data
```{r}
media_agency_df <- read_csv("data_in/media_agency_tweets.csv")
media_agency_df <- media_agency_df[ , colSums(is.na(media_agency_df)) < nrow(media_agency_df)]

```

Wrangeling data
```{r}
picky_mtdf<- media_tweets_df %>%
  select(screen_name,text) %>%
   unnest_tokens("word", text)

data(stop_words)

picky_mtdf <- picky_mtdf %>%
  anti_join(stop_words)

picky_mtdf%>%
  filter(!(word=="https"|
             word=="rt"|
             word=="t.co"|
             word=="amp")) %>%
  count(word, sort=TRUE)
```
Filtering DF
```{r}
filtered_tweets<- media_tweets_df[grep("covid", media_tweets_df$text), ignore.case = TRUE]
```
Seniment Analysis with SentimentR
```{r}
#cleaning

media_agency_df <- media_agency_df %>%
  mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text),
         text = gsub("&amp", "", text),
         text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text),
         text = gsub("@\\w+", "", text),
         text = gsub("[[:punct:]]", "", text),
         text = gsub("[[:digit:]]", "", text),
         text = gsub("http\\w+", "", text),
         text = gsub("[ \t]{2,}", "", text),
         text = gsub("^\\s+|\\s+$", "", text),
         text = gsub("&amp", "", text)) %>%
  mutate(text = str_replace_all(text," "," "),
         text = str_replace_all(text,"RT @[a-z,A-Z]*: "," "),
         text = str_replace_all(text,"#[a-z,A-Z]*"," "),
         text = str_replace_all(text,"@[a-z,A-Z]*"," "))
 
 
mytext<- media_agency_df%>%
  select(text) 
mytext <- get_sentences(mytext)
sr_data <-sentiment(mytext)
write_csv(sr_data,"data_in/sentimentr_data.csv")
```
Adding time data to sentiment df
```{r}
time_data <- media_agency_df %>%
  select(X1,created_at,screen_name)

SentiR_data <-left_join(time_data,sr_data,
                        by=c("X1"="element_id"))
write_csv(SentiR_data,"data_in/sr_df_time.csv")

```

Modeling the time data
```{r}
#setting the date format
SentiR_data$created_at = ymd_hms(SentiR_data$created_at)

```




#Kyles Code
Topic Modelling
```{r}
tidy_covid_media_df <- media_agency_df %>%
  #filter(str_detect(text, fixed(covid_dictionary, ignore_case = TRUE))) %>%
  filter(!str_detect(text, "^RT")) %>%
  mutate(text = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", text)) %>%
  unnest_tokens(word, text, token = "tweets") %>%
  filter(!word %in% stop_words$word,
         !word %in% str_remove_all(stop_words$word, "'"),
         str_detect(word, "[a-z]"),
         !(word =="#sabcnews" |
             word =="#enca" |
             word =="https" |
             word =="#dstv403" |
             word =="t.co" |
             word =="rt" |
             word =="amp"))
tidy_matrix <- tidy_covid_media_df %>% count(screen_name, word) %>% cast_dfm(screen_name, word, n)

 
media_lda <- LDA(tidy_matrix, k = 4, control = list(seed = 1234))
media_lda
media_topics <- tidy(media_lda, matrix = "beta")
media_topics
media_top_terms <- media_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
 

media_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
```
Vader stuff
```{r}
vader_data<- read_csv("data_in/vader_df.csv")
```

